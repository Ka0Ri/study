{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0ECUl3CDiLo"
      },
      "source": [
        "# Tutorial 2 (JAX): Introduction to JAX+Flax\n",
        "\n",
        "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=green)\n",
        "\n",
        "**Filled notebook:**\n",
        "[![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.ipynb)\n",
        "[![Open filled In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.ipynb)   \n",
        "**Author:** Phillip Lippe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrAGx7HsDiLq"
      },
      "source": [
        "Welcome to our JAX tutorial for the Deep Learning course at the University of Amsterdam! The following notebook is meant to give a short introduction to JAX, including writing and training your own neural networks with [Flax](https://flax.readthedocs.io/en/latest/). But why should you learn JAX, if there are already so many other deep learning frameworks like [PyTorch](https://pytorch.org/) and [TensorFlow](https://www.tensorflow.org/)? The short answer: because it can be extremely fast. For instance, a small GoogleNet on CIFAR10, which we discuss in detail in [Tutorial 5](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial5/Inception_ResNet_DenseNet.html), can be trained in JAX 3x faster than in PyTorch with a similar setup. Note that for larger models, larger batch sizes, or smaller GPUs, a considerably smaller speedup is expected, and the code has not been designed for benchmarking. Nonetheless, JAX enables this speedup by compiling functions and numerical programs for accelerators (GPU/TPU) *just in time*, finding the optimal utilization of the hardware. Frameworks with dynamic computation graphs like PyTorch cannot achieve the same efficiency, since they cannot anticipate the next operations before the user calls them. For example, in an Inception block of GoogleNet, we apply multiple convolutional layers in parallel on the same input. JAX can optimize the execution of this layer by compiling the whole forward pass for the available accelerator and fusing operations where possible, reducing memory access and speeding up execution. In contrast, when calling the first convolutional layer in PyTorch, the framework does not know that multiple convolutions on the same feature map will follow. It sends each operation one by one to the GPU, and can only adapt the execution after seeing the next Python calls. Hence, JAX can make more efficient use of the GPU than, for instance, PyTorch.\n",
        "\n",
        "However, everything comes with a price. In order to efficiently compile programs just-in-time in JAX, the functions need to be written with certain constraints. Firstly, the functions are not allowed to have side-effects, meaning that they are not allowed to affect any variable outside of their namespaces. For instance, in-place operations affect a variable even outside of the function. Moreover, stochastic operations such as `torch.rand(...)` change the global state of pseudo random number generators, which is not allowed in functional JAX (we will see later how JAX handles random number generation). Secondly, JAX compiles the functions based on anticipated shapes of all arrays/tensors in the function. This becomes problematic if the shapes or the program flow within the function depends on the values of the tensor. For instance, in the operation `y = x[x>3]`, the shape of `y` depends on how many values of `x` are greater than 3. We will discuss more of these constraints in this notebook. Still, in most common cases of training neural networks, it is straightforward to write functions within these constraints.\n",
        "\n",
        "This tutorial is heavily inspired by many great JAX tutorials before, and a (non-exclusive) list of them are:\n",
        "\n",
        "* [JAX 101](https://jax.readthedocs.io/en/latest/jax-101/index.html) with many subtutorials on individual parts of JAX\n",
        "* [JAX - The Sharp Bits](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html) discusses the constraints of JAX and how to overcome them\n",
        "* [Jax for the Impatient](https://flax.readthedocs.io/en/latest/notebooks/jax_for_the_impatient.html) for a quick intro to JAX with focus on deep learning\n",
        "* [Flax Basics](https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html) as introduction to the Flax framework\n",
        "\n",
        "Throughout this tutorial, we will draw comparisons to PyTorch and also use its data loading library (see our [PyTorch tutorial](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html) for a refresher). JAX is not meant to 'redefine the wheel', so we can combine it framework-agnostic parts from PyTorch (e.g., data loading) and TensorFlow (e.g., logging in TensorBoard). Further, we use [Flax](https://flax.readthedocs.io/en/latest/) as a neural network library in JAX, and [Optax](https://optax.readthedocs.io/en/latest/index.html) to implement common deep learning optimizers. More on them later in the notebook. First, let's get started with some basic JAX operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IgEyfw2LDiLq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\197796\\AppData\\Local\\Temp\\ipykernel_13448\\2052077244.py:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('svg', 'pdf') # For export\n",
            "c:\\Users\\197796\\Anaconda3\\envs\\jax\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgba\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWwQKQm-DiLr"
      },
      "source": [
        "## JAX as NumPy on accelerators\n",
        "\n",
        "Every deep learning framework has its own API for dealing with data arrays. For example, PyTorch uses `torch.Tensor` as data arrays on which it defines several operations like matrix multiplication, taking the mean of the elements, etc. In JAX, this basic API strongly resembles the one of [NumPy](https://numpy.org/), and even has the same name in JAX (`jax.numpy`). So, for now, let's think of JAX as NumPy that runs on accelerators. As a first step, let's import JAX and its NumPy API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eMwfSMs6DiLr",
        "outputId": "e8255903-e878-4407-9996-a1fe4f5556aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using jax 0.4.23\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "print(\"Using jax\", jax.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61iYNj3dDiLs"
      },
      "source": [
        "At the current time of writing (June 2022), the newest JAX version is `0.3.13` which supports most of the common NumPy functionalities. The NumPy API of JAX is usually imported as `jnp`, to keep a resemblance to NumPy's import as `np`. In the following subsections, we will discuss the main differences between the classical NumPy API and the one of JAX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiyUjP9pDiLs"
      },
      "source": [
        "### Device Arrays\n",
        "\n",
        "As a first test, let's create some arbitrary arrays like we would do in NumPy. For instance, let's create an array of zeros with shape `[2,5]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yUnBJDNODiLs",
        "outputId": "6c040481-d8ea-42e7-8159-d1e4be354e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "a = jnp.zeros((2, 5), dtype=jnp.float32)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvSXtr-TDiLt"
      },
      "source": [
        "Similarly, we can create an array with values of 0 to 5 by using `arange`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WRYy6WKIDiLt",
        "outputId": "f8a542f8-82c6-4423-acba-23596d195210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "b = jnp.arange(6)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg2WNeh8DiLt"
      },
      "source": [
        "You might now wonder whether the arrays `a` and `b` are simply NumPy arrays. To check that, let's print out the class of `b`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0pV8qeM7DiLt",
        "outputId": "58448f4e-ec04-41ff-cc52-61935811d807"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "jaxlib.xla_extension.ArrayImpl"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.__class__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmKgtXxeDiLt"
      },
      "source": [
        "Instead of a simple NumPy array, it shows the type `DeviceArray` which is what JAX uses to represent arrays. In contrast to NumPy, JAX can execute the same code on different backends – CPU, GPU and TPU. A `DeviceArray` therefore represents an array which is on one of the backends. Similar to PyTorch, we can check the device of an array by calling `.device()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0yU1AgPEDiLt",
        "outputId": "190ab24f-d603-4eeb-c574-70d7f5ba77a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\197796\\AppData\\Local\\Temp\\ipykernel_13448\\2260305871.py:1: DeprecationWarning: arr.device() is deprecated. Use arr.devices() instead.\n",
            "  b.device()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CpuDevice(id=0)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2oBjeacDiLt"
      },
      "source": [
        "As you can see, the array `b` is already natively on a GPU although we did not specify this explicitly as you would do in PyTorch (on Colab, remember to select a GPU in your runtime environment). In order to change the device of an array, we can use `jax.device_get`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ezoQb086DiLt",
        "outputId": "73eb7aee-ae85-4a63-f820-ada2af005ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "b_cpu = jax.device_get(b)\n",
        "print(b_cpu.__class__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AocOsaQKDiLu"
      },
      "source": [
        "Unsurprisingly, a simple CPU-based array is nothing else than a NumPy array, which allows for a simple conversion between the two frameworks! To explicitly push a NumPy array to the accelerator, you can use `jax.device_put`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4_rifI-wDiLu",
        "outputId": "f863b36c-f873-4f52-81aa-d6d22af5e5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device put: <class 'jaxlib.xla_extension.ArrayImpl'> on TFRT_CPU_0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\197796\\AppData\\Local\\Temp\\ipykernel_13448\\953025352.py:2: DeprecationWarning: arr.device() is deprecated. Use arr.devices() instead.\n",
            "  print(f'Device put: {b_gpu.__class__} on {b_gpu.device()}')\n"
          ]
        }
      ],
      "source": [
        "b_gpu = jax.device_put(b_cpu)\n",
        "print(f'Device put: {b_gpu.__class__} on {b_gpu.device()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUqBVQZODiLu"
      },
      "source": [
        "Nicely enough, JAX will handle any device clash itself when you try to perform operations on a NumPy array and a DeviceArray by modeling the output as DeviceArray again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UsyKnLhZDiLu",
        "outputId": "58e6f267-5273-4c6c-db59-50aac6da7bf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([ 0,  2,  4,  6,  8, 10], dtype=int32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b_cpu + b_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g8qyWRqDiLu"
      },
      "source": [
        "Finally, we can also print all our available devices using `jax.devices()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WaFVvzddDiLu",
        "outputId": "cee5f9c6-190b-4f21-a7c3-bface706b1c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[CpuDevice(id=0)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bBpOg28DiLu"
      },
      "source": [
        "A technical detail of running operations on DeviceArrays is that when a JAX function is called, the corresponding operation takes place asynchronously on the accelerator when possible. For instance, if we call `out = jnp.matmul(b, b)`, JAX first returns a placeholder array for `out` which may not be filled with the values as soon as the function calls finishes. This way, Python will not block the execution of follow-up statements, but instead only does it whenever we strictly need the value of `out`, for instance for printing or putting it on CPU. PyTorch uses a very similar principle to allow asynchronous computation. For more details, see [JAX - Asynchronous Dispatch](https://jax.readthedocs.io/en/latest/async_dispatch.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_sy8pyUDiLu"
      },
      "source": [
        "### Immutable tensors\n",
        "\n",
        "When we would like to change a NumPy array in-place, like replacing the first element of `b` with `1` instead of `0`, we could simply write `b[0]=1`. However, in JAX, this is not possible. A `DeviceArray` object is *immutable*, which means that no in-place operations are possible. The reason for this goes back to our discussion in the introduction: JAX requires programs to be \"pure\" functions, i.e. no effects on variables outside of the function are allowed. Allowing in-place operations of variables would make the program analysis for JAX's just-in-time compilation difficult. Instead, we can use the expression `b.at[0].set(1)` which, analogous to the in-place operation, returns a new array which is identical to `b`, except that its value at the first position is 1. Let's try that out below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "unIUNC77DiLu",
        "outputId": "854b54f5-12a9-4729-9996-06f27764417e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original array: [0 1 2 3 4 5]\n",
            "Changed array: [1 1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "b_new = b.at[0].set(1)\n",
        "print('Original array:', b)\n",
        "print('Changed array:', b_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKliHs-vDiLu"
      },
      "source": [
        "However, we said that JAX is very efficient. Isn't creating a new array in this case the opposite? While it is indeed less efficient, it can made much more efficient with JAX's just-in-time compilation. The compiler can recognize unnecessary array duplications, and replace them with in-place operations again. More on the just-in-time compilation later!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky6TnipLDiLu"
      },
      "source": [
        "### Pseudo Random Numbers in JAX\n",
        "\n",
        "In machine learning, we come across several situations where we need to generate pseudo random numbers: randomly shuffling a dataset, sampling a dropout mask for regularization, training a VAE by sampling from the approximate posterior, etc. In libraries like NumPy and PyTorch, the random number generator are controlled by a seed, which we set initially to obtain the same samples every time we run the code (this is why the numbers are not truly random, hence \"pseudo\"-random). However, if we call `np.random.normal()` 5 times consecutively, we will get 5 different numbers since every execution changes the state/seed of the pseudo random number generation (PRNG). In JAX, if we would try to generate a random number with this approach, a function creating pseudo-random number would have an effect outside of it. To prevent this, JAX takes a different approach by explicitly passing and iterating the PRNG state. First, let's create a PRNG for the seed 42:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jzKOtn8kDiLu"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcOW-7EeDiLu"
      },
      "source": [
        "Now, we can use this PRNG state to generate random numbers. Since with this state, the random number generation becomes deterministic, we sample the same number every time. This is not the case in NumPy if we set the seed once before both operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PFf2K4J9DiLu",
        "outputId": "d59fd1a3-4c5c-4194-e033-a4197c8738da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JAX - Random number 1: -0.18471177\n",
            "JAX - Random number 2: -0.18471177\n",
            "NumPy - Random number 1: 0.4967141530112327\n",
            "NumPy - Random number 2: -0.13826430117118466\n"
          ]
        }
      ],
      "source": [
        "# A non-desirable way of generating pseudo-random numbers...\n",
        "jax_random_number_1 = jax.random.normal(rng)\n",
        "jax_random_number_2 = jax.random.normal(rng)\n",
        "print('JAX - Random number 1:', jax_random_number_1)\n",
        "print('JAX - Random number 2:', jax_random_number_2)\n",
        "\n",
        "# Typical random numbers in NumPy\n",
        "np.random.seed(42)\n",
        "np_random_number_1 = np.random.normal()\n",
        "np_random_number_2 = np.random.normal()\n",
        "print('NumPy - Random number 1:', np_random_number_1)\n",
        "print('NumPy - Random number 2:', np_random_number_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAdfW8ceDiLu"
      },
      "source": [
        "Usually, we want to have a behavior like NumPy where we get a different random number every time we sample. To achieve this, we can *split* the PRNG state to get usable subkeys every time we need a new pseudo-random number. We can do this with `jax.random.split(...)`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-MfyO0iDDiLu",
        "outputId": "2b806987-6b34-4ad3-c719-23413705ee0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JAX new - Random number 1: 1.5323194\n",
            "JAX new - Random number 2: 1.2775489\n"
          ]
        }
      ],
      "source": [
        "rng, subkey1, subkey2 = jax.random.split(rng, num=3)  # We create 3 new keys\n",
        "jax_random_number_1 = jax.random.normal(subkey1)\n",
        "jax_random_number_2 = jax.random.normal(subkey2)\n",
        "print('JAX new - Random number 1:', jax_random_number_1)\n",
        "print('JAX new - Random number 2:', jax_random_number_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKp2hp32DiLu"
      },
      "source": [
        "Every time you run this cell, you will obtain different random numbers for both operations since we create new PRNG states before sampling. In general, you want to split the PRNG key every time before generating a pseudo-number, to prevent accidentally obtaining the exact same numbers (for instance, sampling the exact same dropout mask every time you run the network makes dropout itself quite useless...). For a deeper dive into the ideas behind the random number generation in JAX, see JAX's tutorial on [Pseudo Random Numbers](https://jax.readthedocs.io/en/latest/jax-101/05-random-numbers.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7M5Gc0IDiLv"
      },
      "source": [
        "## Function transformations with Jaxpr\n",
        "\n",
        "Rosalia Schneider and Vladimir Mikulik summarize the key points of JAX in the [JAX 101 tutorial](https://jax.readthedocs.io/en/latest/jax-101/01-jax-basics.html) as follows:\n",
        "\n",
        "> The most important difference, and in some sense the root of all the rest, is that JAX is designed to be functional, as in functional programming. The reason behind this is that the kinds of program transformations that JAX enables are much more feasible in functional-style programs. [...] The important feature of functional programming to grok when working with JAX is very simple: don’t write code with side-effects.\n",
        "\n",
        "Essentially, we want to write our main code of JAX in functions that do not affect anything else besides its outputs. For instance, we do not want to change input arrays in-place, or access global variables. While this might seem limiting at first, you get used to this quite quickly and most JAX functions that need to fulfill these constraints can be written this way without problems. Note that not all possible functions in training a neural network need to fulfill the constraints. For instance, loading or saving of models, the logging, or the data generation can be done in naive functions. Only the network execution, which we want to do very efficiently on our accelerator (GPU or TPU), should strictly follow these constraints.\n",
        "\n",
        "What does make JAX functions so special, and how can we think about them? A good way of gaining understanding in how JAX handles function is to understand its intermediate representation: jaxpr. Conceptually, you can think of any operation that JAX does on a function, as first trace-specializing the Python function to be transformed into a small and well-behaved intermediate form. This means that we check which operations are performed on which array, and what shapes the arrays are. Based on this representation, JAX then interprets the function with transformation-specific interpretation rules, which includes automatic differentiation or compiling a function in XLA to efficiently use the accelerator.\n",
        "\n",
        "To illustrate this intermediate representation, let's consider the same simple function we used in the [PyTorch tutorial](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html) to discuss the concept of dynamic computation graphs:\n",
        "\n",
        "$$ y = \\frac{1}{|x|}\\sum_{i}\\left[\\left(x_i+2\\right)^2+3\\right]$$\n",
        "\n",
        "Using common NumPy operations in JAX, we can write it as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GK7Tn1N2DiLv",
        "outputId": "63e4f123-8724-4e09-a49c-72102dedda12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input [0. 1. 2.]\n",
            "Output 12.666667\n"
          ]
        }
      ],
      "source": [
        "def simple_graph(x):\n",
        "    x = x + 2\n",
        "    x = x ** 2\n",
        "    x = x + 3\n",
        "    y = x.mean()\n",
        "    return y\n",
        "\n",
        "inp = jnp.arange(3, dtype=jnp.float32)\n",
        "print('Input', inp)\n",
        "print('Output', simple_graph(inp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Dy3LJ_DiLv"
      },
      "source": [
        "To view the jaxpr representation of this function, we can use `jax.make_jaxpr`. Since the tracing depends on the shape of the input, we need to pass an input to the function (here of shape `[3]`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wyzn-buHDiLv",
        "outputId": "0da5363d-9227-4263-bb39-cea40dd66e2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[3]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
              "    \u001b[39m\u001b[22m\u001b[22mb\u001b[35m:f32[3]\u001b[39m = add a 2.0\n",
              "    c\u001b[35m:f32[3]\u001b[39m = integer_pow[y=2] b\n",
              "    d\u001b[35m:f32[3]\u001b[39m = add c 3.0\n",
              "    e\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0,)] d\n",
              "    f\u001b[35m:f32[]\u001b[39m = div e 3.0\n",
              "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(f,) }"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.make_jaxpr(simple_graph)(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQaZaJm_DiLv"
      },
      "source": [
        "A jaxpr representation follows the structure:\n",
        "\n",
        "```python\n",
        "jaxpr ::= { lambda Var* ; Var+.\n",
        "            let Eqn*\n",
        "            in  [Expr+] }\n",
        "```\n",
        "where `Var*` are constants and `Var+` are input arguments. In the cell above, this is `a:f32[3]`, i.e. an array of shape 3 with type `jnp.float32` (`inp`). The list of equations, `Eqn*`, define the intermediate results of the function. You can see that each operation in `simple_graph` is translated to a corresponding equation, like `x = x + 2` is translated to `b:f32[3] = add a 2.0`. Furthermore, you see the specialization of the operations on the input shape, like `x.mean()` being replacing in `e` and `f` with summing and dividing by 3. Finally, `Expr+` in the jaxpr representation are the outputs of the functions. In the example, this is `f`, i.e. the final result of the function.\n",
        "Based on these atomic operations, JAX offers all kind of function transformations, of which we will discuss the most important ones later in this section.\n",
        "Hence, you can consider the jaxpr representation is an intermediate compilation stage of JAX. What happens if we actually try to look at the jaxpr representation of a function with side-effect? Let's consider the following function, which, as an illustrative example, appends the input to a global list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7PcCanCmDiLv",
        "outputId": "5ba537ec-91d1-4eb7-cd33-89b1d83e86a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[3]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
              "    \u001b[39m\u001b[22m\u001b[22mb\u001b[35m:f32[3]\u001b[39m = integer_pow[y=2] a\n",
              "    c\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0,)] b\n",
              "    d\u001b[35m:f32[]\u001b[39m = sqrt c\n",
              "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(d,) }"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "global_list = []\n",
        "\n",
        "# Invalid function with side-effect\n",
        "def norm(x):\n",
        "    global_list.append(x)\n",
        "    x = x ** 2\n",
        "    n = x.sum()\n",
        "    n = jnp.sqrt(n)\n",
        "    return n\n",
        "\n",
        "jax.make_jaxpr(norm)(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzsstWDFDiLx"
      },
      "source": [
        "As you can see, the jaxpr representation of the function does not contain any operation for `global_list.append(x)`. This is because jaxpr only understand side-effect-free code, and cannot represent such effects. Thus, we need to stick with pure functions without any side effects, to prevent any unwanted errors in our functions. If you are interested in learning more about the jaxpr representation, check out the JAX [documentation](https://jax.readthedocs.io/en/latest/jaxpr.html) on it. But for this tutorial, we just need the basics as discussed above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChAz43qgDiLy"
      },
      "source": [
        "### Automatic differentiation\n",
        "\n",
        "The intermediate jaxpr representation defines a computation graph, on which we can perform an essential operation of deep learning framework: automatic differentiation. In frameworks like PyTorch with a dynamic computation graph, we would compute the gradients based on the loss tensor itself, e.g. by calling `loss.backward()`. However, JAX directly works with functions. Instead of backpropagating gradients through tensors, JAX takes as input a function, and outputs another function which directly calculates the gradients for it. While this might seem quite different to what you are used to from other frameworks, it is quite intuitive: your gradient of parameters is really a function of parameters and data.\n",
        "\n",
        "The transformation that allows us to do this is `jax.grad`, which takes as input the function, and returns another function representing the gradient calculation of the (first) input with respect to the output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Zxuos6goDiLy",
        "outputId": "992173b7-17df-42e4-91b4-e64d54744db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient [1.3333334 2.        2.6666667]\n"
          ]
        }
      ],
      "source": [
        "grad_function = jax.grad(simple_graph)\n",
        "gradients = grad_function(inp)\n",
        "print('Gradient', gradients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkfbNnzwDiLy"
      },
      "source": [
        "The gradient we get here is exactly the one we would obtain when doing the calculation by hand. Moreover, we can also print the jaxpr representation of the gradient function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pkijjkI7DiLy",
        "outputId": "a61b0dec-abc4-4140-c912-f4431e0812d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[3]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
              "    \u001b[39m\u001b[22m\u001b[22mb\u001b[35m:f32[3]\u001b[39m = add a 2.0\n",
              "    c\u001b[35m:f32[3]\u001b[39m = integer_pow[y=2] b\n",
              "    d\u001b[35m:f32[3]\u001b[39m = integer_pow[y=1] b\n",
              "    e\u001b[35m:f32[3]\u001b[39m = mul 2.0 d\n",
              "    f\u001b[35m:f32[3]\u001b[39m = add c 3.0\n",
              "    g\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0,)] f\n",
              "    _\u001b[35m:f32[]\u001b[39m = div g 3.0\n",
              "    h\u001b[35m:f32[]\u001b[39m = div 1.0 3.0\n",
              "    i\u001b[35m:f32[3]\u001b[39m = broadcast_in_dim[broadcast_dimensions=() shape=(3,)] h\n",
              "    j\u001b[35m:f32[3]\u001b[39m = mul i e\n",
              "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(j,) }"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.make_jaxpr(grad_function)(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZdVfmrqDiLy"
      },
      "source": [
        "This shows an unique property of JAX: we can print out the exact computation graph for determining the gradients. Compared to the original function, you can see new equations like `d:f32[3] = integer_pow[y=1] b` and `e:f32[3] = mul 2.0 d`, which model the intermediate gradient of $\\partial b_i^2/\\partial b_i = 2b_i$. Furthermore, the return value `j` is the multiplication of `e` with $1/3$, which maps to the gradient being:\n",
        "\n",
        "$$ \\frac{\\partial y}{\\partial x_i} = \\frac{2}{3}(x_i + 2)$$\n",
        "\n",
        "Hence, we can not only use JAX to estimate the gradients at a certain input value, but actually return the analytical gradient function which is quite a nice feature and highlights the properties of JAX!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ysDYyhDiLy"
      },
      "source": [
        "Often, we do not only want the gradients, but also the actual output of the function, for instance for logging the loss. This can be efficiently done using `jax.value_and_grad`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "I2arwn-dDiLy",
        "outputId": "0c433572-c5b3-43f1-c41c-f3bb1101cdc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Array(12.666667, dtype=float32),\n",
              " Array([1.3333334, 2.       , 2.6666667], dtype=float32))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_grad_function = jax.value_and_grad(simple_graph)\n",
        "val_grad_function(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsxnVcPbDiLy"
      },
      "source": [
        "Further, we can specialize the gradient function to consider multiple input arguments, and add extra outputs that we may not want to differentiate (for instance the accuracy in classification). We will visit the most important ones in the network training later in this section, and refer to other great resources for more details ([JAX Quickstart](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#taking-derivatives-with-grad), [Autodiff cookbook](https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html), [Advanced autodiff](https://jax.readthedocs.io/en/latest/jax-101/04-advanced-autodiff.html)).\n",
        "\n",
        "To train neural networks, we need to determine the gradient for every parameter in the network with respect to the loss. Listing all parameters as input arguments quickly gets annoying and infeasible. JAX offers an elegant data structure to summarize all parameters: a pytree ([documentation](https://jax.readthedocs.io/en/latest/pytrees.html)). A pytree is a container-like object which structures its elements as a tree. For instance, a linear neural network might have its parameters organized similar to:\n",
        "\n",
        "```python\n",
        "params = {\n",
        "    'linear1': {\n",
        "        'weights': ...,\n",
        "        'bias': ...\n",
        "    },\n",
        "    ...\n",
        "}\n",
        "```\n",
        "JAX offers functions to process pytrees efficiently, such as obtaining all leafs (i.e. all parameters in a network) or applying a function on each element. We will come back to these structures when training a full network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaAsZO9ADiLy"
      },
      "source": [
        "### Speeding up computation with Just-In-Time compilation\n",
        "\n",
        "Interestingly, from the previous code cell, you can see in the jaxpr representation of the gradient function that calculating the array `f` and scalar `g` are unnecessary. Intuitively, the gradient of taking the mean is independent of the actual output of the mean, hence we could drop `f` and `g` without any drawback. Finding such cases to improve efficiency and optimizing the code to take full advantage of the available accelerator hardware is one of the big selling points of JAX. It achieves that by *compiling functions just-in-time* with [XLA](https://www.tensorflow.org/xla) (Accelerated Linear Algebra), using their jaxpr representation. Thereby, XLA fuses operations to reduce execution time of short-lived operations and eliminates intermediate storage buffers where not needed. For more details, see the [XLA documentation](https://docs.w3cub.com/tensorflow~guide/performance/xla/index).\n",
        "\n",
        "To compile a function, JAX provides the `jax.jit` transformation. We can either apply the transformation directly on a function (as we will do in the next cell), or use the decorator `@jax.jit` before a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "guxSn3wwDiLy"
      },
      "outputs": [],
      "source": [
        "jitted_function = jax.jit(simple_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro-lypVgDiLy"
      },
      "source": [
        "The `jitted_function` takes the same input arguments as the original function `simple_graph`. Since the jaxpr representation of a function depends on the input shape, the compilation is started once we put the first input in. However, note that this also means that for every different shape we want to run the function, a new XLA compilation is needed. This is why it is recommended to use padding in cases where your input shape strongly varies (we revisit this topic in the final section of this tutorial). For now, let's create an array with 1000 random values, on which we apply the jitted function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DF5srBo0DiLy"
      },
      "outputs": [],
      "source": [
        "# Create a new random subkey for generating new random values\n",
        "rng, normal_rng = jax.random.split(rng)\n",
        "large_input = jax.random.normal(normal_rng, (1000,))\n",
        "# Run the jitted function once to start compilation\n",
        "_ = jitted_function(large_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CTkOWRGDiLy"
      },
      "source": [
        "The output is not any different from what you would get from the non-jitted function. However, how is it about the runtime? Let's time both the original and the jitted function. Due to the asynchronous execution on the GPU, we add `.block_until_ready()` on the output, which blocks the Python execution until the accelerator (here GPU) finished computing the result and hence get an accurate time estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Y06LfSASDiLy",
        "outputId": "5f2897aa-916f-4a84-907d-300f23e12f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67.2 µs ± 315 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "simple_graph(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "j7q-tEJ6DiLy",
        "outputId": "de5715d5-bc41-496e-f41c-89893bbab194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.1 µs ± 13.6 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "jitted_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVyYagj3DiLy"
      },
      "source": [
        "We see that the compiled function is almost 10-15x faster! This is quite an improvement in performance, and shows the potential of compiling functions with XLA. Furthermore, we can also apply multiple transformations on the same function in JAX, such as applying `jax.jit` on a gradient function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yP1usczJDiLy"
      },
      "outputs": [],
      "source": [
        "jitted_grad_function = jax.jit(grad_function)\n",
        "_ = jitted_grad_function(large_input)  # Apply once to compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgjhGipLDiLz"
      },
      "source": [
        "Let's time the functions once more:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HbGI-vzQDiLz",
        "outputId": "6ff1e2d5-4f0d-4ba4-8422-cce2a9f5e499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15 ms ± 35.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "grad_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MObF1w6yDiLz",
        "outputId": "6ce024f3-8781-466a-d776-d15371d52aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.77 µs ± 17.9 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "jitted_grad_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ey0849aDiLz"
      },
      "source": [
        "Once more, the jitted function is much faster than the original one. Intuitively, this shows the potential speed up we can gain by using `jax.jit` to compile the whole training step of a network. Generally, we want to jit the largest possible chunk of computation to give the compiler maximum freedom.\n",
        "\n",
        "There are situations in which applying jit to a function is not straight-forward, for instance, if an input argument cannot be traced, or you need to use loops that depend on input arguments. To keep the tutorial simple, and since most neural network training functions do not run into these issues, we do not discuss such special cases here. Instead, we refer to the section on just-in-time compilation in the great tutorials of [JAX 101 Tutorial](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html), [JAX Quickstart](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#using-jit-to-speed-up-functions), and [Thinking in JAX](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html#to-jit-or-not-to-jit)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ettxKZUuDiLz"
      },
      "source": [
        "## Implementing a Neural Network with Flax\n",
        "\n",
        "With having reviewed the basics of JAX, we are now ready to implement our own neural network. Technically, we could implement our own neural network from scratch with JAX (see [here](https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html) for an example), but we do not really want to do that every time. Similarly to PyTorch's `torch.nn` package, there exist neural network libraries based on JAX which provide such basic functionality. A (non-exclusive) collection of them are:\n",
        "\n",
        "* [Flax](https://flax.readthedocs.io/en/latest/index.html), started by the Google Brain Team, focuses on flexibility and clarity.\n",
        "* [Haiku](https://dm-haiku.readthedocs.io/en/latest/), from DeepMind, focuses on simplicity and compositionality.\n",
        "* [Trax](https://github.com/google/trax), maintained by the Google Brain Team, provides solutions for common training tasks\n",
        "* [Equinox](https://github.com/patrick-kidger/equinox), created by Patrick Kidger and Cristian Garcia, implements neural networks as callable PyTrees\n",
        "* [Jraph](https://github.com/deepmind/jraph), from DeepMind, is a graph neural network library (similar to PyTorch Geometric)\n",
        "\n",
        "For this tutorial series, we will use Flax due to its flexibility, intuitive API, and larger community. However, this should not mean that the other libraries are necessarily worse, and we recommend giving them a try as well to find the best library for yourself!\n",
        "\n",
        "We will introduce the libraries and all additional parts you might need to train a neural network in Flax, using a simple example classifier on a simple yet well known example: XOR. Given two binary inputs $x_1$ and $x_2$, the label to predict is $1$ if either $x_1$ or $x_2$ is $1$ while the other is $0$, or the label is $0$ in all other cases. The example became famous by the fact that a single neuron, i.e. a linear classifier, cannot learn this simple function. Hence, we will learn how to build a small neural network that can learn this function.\n",
        "To make it a little bit more interesting, we move the XOR into continuous space and introduce some gaussian noise on the binary inputs. Our desired separation of an XOR dataset could look as follows:\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/continuous_xor.svg?raw=1\" width=\"350px\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2_qWYCgDiLz"
      },
      "source": [
        "### The model\n",
        "\n",
        "The package `flax.linen` defines a series of useful classes like linear networks layers, convolutions, activation functions etc. A full list can be found [here](https://flax.readthedocs.io/en/latest/flax.linen.html). In case you need a certain network layer, check the documentation of the package first before writing the layer yourself as the package likely contains the code for it already. We import it below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "J9qEW4-5DiLz"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import flax\n",
        "except ModuleNotFoundError: # Install flax if missing\n",
        "    !pip install --quiet flax\n",
        "    import flax\n",
        "\n",
        "from flax import linen as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eYvRdSyDiLz"
      },
      "source": [
        "#### nn.Module\n",
        "\n",
        "Similar to PyTorch, a neural network is built up out of modules. Modules can contain other modules, and a neural network is considered to be a module itself as well. The basic template of a module is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lfX_dDeNDiLz"
      },
      "outputs": [],
      "source": [
        "class MyModule(nn.Module):\n",
        "    # Some dataclass attributes, like hidden dimension, number of layers, etc. of the form:\n",
        "    # varname : vartype\n",
        "\n",
        "    def setup(self):\n",
        "        # Flax uses \"lazy\" initialization. This function is called once before you\n",
        "        # call the model, or try to access attributes. In here, define your submodules etc.\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Function for performing the calculation of the module.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R0ScktFDiLz"
      },
      "source": [
        "The main, obvious difference to PyTorch is that Flax uses lazy initialization. The function `setup` is called once on a module instance before any other methods are called, or when you try to access a attribute of *self* defined in setup. Additional object attributes are defined below the class name. However, in contrast to PyTorch, the parameters are not part of the module. Instead, we can create a set of parameters of the module by calling its `init()` function. This function takes as input a PRNG state for sampling pseudo-random numbers and an example input to the model, and returns a set of parameters for the module as a pytree. Further, since the init function requires an input to the network, we can infer the input shape for all modules and do not need to explicitly define it during the module creation. This becomes more clear in the example we show in a second.\n",
        "\n",
        "The `__call__` method represents the `forward` function in PyTorch, and performs the actual computation of the module. It can take additional arguments if needed, like whether we are training or validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP0mWZjhDiLz"
      },
      "source": [
        "#### Simple classifier\n",
        "\n",
        "To get an intuition behind how we work with modules in Flax, let's define our own small neural network. We will use a minimal network with a input layer, one hidden layer with tanh as activation function, and a output layer. In other words, our networks should look something like this:\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/small_neural_network.svg?raw=1\" width=\"300px\"></center>\n",
        "\n",
        "The input neurons are shown in blue, which represent the coordinates $x_1$ and $x_2$ of a data point. The hidden neurons including a tanh activation are shown in white, and the output neuron in red.\n",
        "In Flax, we can define this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "M6AHavK5DiLz"
      },
      "outputs": [],
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "    num_hidden : int   # Number of hidden neurons\n",
        "    num_outputs : int  # Number of output neurons\n",
        "\n",
        "    def setup(self):\n",
        "        # Create the modules we need to build the network\n",
        "        # nn.Dense is a linear layer\n",
        "        self.linear1 = nn.Dense(features=self.num_hidden)\n",
        "        self.linear2 = nn.Dense(features=self.num_outputs)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.linear1(x)\n",
        "        x = nn.tanh(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6xqjuSvDiLz"
      },
      "source": [
        "One thing you may notice is that usually, all layers that we define in `setup` are also used in the `__call__` function. To reduce the code overhead, Flax provides an alternative, more compact network creation with `nn.compact`. With that, we can remove the setup function and instead our model as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "1fQLd0ZLDiLz"
      },
      "outputs": [],
      "source": [
        "class SimpleClassifierCompact(nn.Module):\n",
        "    num_hidden : int   # Number of hidden neurons\n",
        "    num_outputs : int  # Number of output neurons\n",
        "\n",
        "    @nn.compact  # Tells Flax to look for defined submodules\n",
        "    def __call__(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        # while defining necessary layers\n",
        "        x = nn.Dense(features=self.num_hidden)(x)\n",
        "        x = nn.tanh(x)\n",
        "        x = nn.Dense(features=self.num_outputs)(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeZW2xTcDiLz"
      },
      "source": [
        "The `nn.compact` annotation of the `__call__` method signals Flax to look for submodules that we define in the forward pass. These are automatically recognized as such, so that we can use them for initialization etc. Which of the two model definition you use is often up to you (see the [Flax documentation](https://flax.readthedocs.io/en/latest/design_notes/setup_or_nncompact.html) for some pros and cons for both methods). In the following tutorials, we will mostly use the compact version, but occasionally come back to the explicit setup function where necessary. For instance, if we define more functions on a module besides `__call__` and want to reuse some modules, it is recommended to use the setup version."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZvgYPiZDiLz"
      },
      "source": [
        "For the examples in this notebook, we will use a tiny neural network with two input neurons and eight hidden neurons. As we perform binary classification, we will use a single output neuron. Note that we do not apply a sigmoid on the output yet. This is because other functions, especially the loss, are more efficient and precise to calculate on the original outputs instead of the sigmoid output. We will discuss the detailed reason later.\n",
        "\n",
        "Now, let's create an instance of this network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "icGomCj5DiLz",
        "outputId": "5e16ccf5-63c4-4752-c682-6798a866a0cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimpleClassifier(\n",
            "    # attributes\n",
            "    num_hidden = 4\n",
            "    num_outputs = 1\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = SimpleClassifier(num_hidden=4, num_outputs=1)\n",
        "# Printing the model shows its attributes\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsLl_LTHDiLz"
      },
      "source": [
        "At this stage, the model has no parameters initialized. To do this, let's create a random input of our dataset, and apply the init function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Z3bJmb22DiLz",
        "outputId": "cefb4590-467a-4f46-b640-6d2b748cfeb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'params': {'linear1': {'kernel': Array([[ 0.13510415, -0.5242738 ,  0.95488465, -1.3176621 ],\n",
            "       [-0.3141359 ,  1.0956402 , -1.1870086 , -0.03833633]],      dtype=float32), 'bias': Array([0., 0., 0., 0.], dtype=float32)}, 'linear2': {'kernel': Array([[ 0.09607014],\n",
            "       [-0.15327907],\n",
            "       [-0.22433403],\n",
            "       [-0.14053574]], dtype=float32), 'bias': Array([0.], dtype=float32)}}}\n"
          ]
        }
      ],
      "source": [
        "rng, inp_rng, init_rng = jax.random.split(rng, 3)\n",
        "inp = jax.random.normal(inp_rng, (1, 2))  # Batch size 8, input size 2\n",
        "# Initialize the model\n",
        "params = model.init(init_rng, inp)\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL4ewnO1DiL0"
      },
      "source": [
        "Now, we have parameters with which we can apply the network. We see that the parameters follow the same structure as defined in our module, and each linear layer contains one `kernel`, i.e. the weights, and a bias parameter. With this, we could apply the model on an input using the `apply` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "PZfXTypODiL0",
        "outputId": "5289acbb-7233-44f4-e97a-82e7cb3d4ab3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[-0.02841723]], dtype=float32)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.apply(params, inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZHbGuHRDiL0"
      },
      "source": [
        "The model returns an output array of shape `[8,1]`, which corresponds to the one output neuron in the model for all 8 batch elements. With that, we now know how to initialize a model, and run a model. Next, let's look at the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3c5nuWiDiL0"
      },
      "source": [
        "### The data\n",
        "\n",
        "As mentioned before, JAX is not meant to 'reinvent the wheel' for every part of the deep learning pipeline. Hence, JAX and Flax do not natively provide a data loading functionality, but instead refer to other available libraries like Tensorflow and PyTorch. Here, let's use again the package `torch.utils.data` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "sJp1vBz1DiL0"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1hhqqMvDiL0"
      },
      "source": [
        "The data package defines two classes which are the standard interface for handling data in PyTorch: `data.Dataset`, and `data.DataLoader`. The dataset class provides an uniform interface to access the training/test data, while the data loader makes sure to efficiently load and stack the data points from the dataset into batches during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PnC0_KDiL0"
      },
      "source": [
        "#### The dataset class\n",
        "\n",
        "The dataset class summarizes the basic functionality of a dataset in a natural way. To define a dataset in PyTorch, we simply specify two functions: `__getitem__`, and `__len__`. The get-item function has to return the $i$-th data point in the dataset, while the len function returns the size of the dataset. For the XOR dataset, we can define the dataset class as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "b8PGslMfDiL0"
      },
      "outputs": [],
      "source": [
        "class XORDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, size, seed, std=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            size - Number of data points we want to generate\n",
        "            seed - The seed to use to create the PRNG state with which we want to generate the data points\n",
        "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.np_rng = np.random.RandomState(seed=seed)\n",
        "        self.std = std\n",
        "        self.generate_continuous_xor()\n",
        "\n",
        "    def generate_continuous_xor(self):\n",
        "        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n",
        "        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n",
        "        # If x=y, the label is 0.\n",
        "        data = self.np_rng.randint(low=0, high=2, size=(self.size, 2)).astype(np.float32)\n",
        "        label = (data.sum(axis=1) == 1).astype(np.int32)\n",
        "        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n",
        "        data += self.np_rng.normal(loc=0.0, scale=self.std, size=data.shape)\n",
        "\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return the idx-th data point of the dataset\n",
        "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
        "        data_point = self.data[idx]\n",
        "        data_label = self.label[idx]\n",
        "        return data_point, data_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV49chQkDiL0"
      },
      "source": [
        "Note that in contrast to our [PyTorch tutorial](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html#The-data), we use NumPy to generate the random data. Similar to JAX, NumPy also allows the pseudo-number generation based on a PRNG state. Hence, for better reproducibility, we are doing the same here. Let's try to create such a dataset and inspect it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "NhevyzNVDiL0",
        "outputId": "db609eae-e93d-43cf-a178-35157a93872c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of dataset: 200\n",
            "Data point 0: (array([-0.06800247,  1.0232254 ], dtype=float32), 1)\n"
          ]
        }
      ],
      "source": [
        "dataset = XORDataset(size=200, seed=42)\n",
        "print(\"Size of dataset:\", len(dataset))\n",
        "print(\"Data point 0:\", dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYS89cJ1DiL0"
      },
      "source": [
        "To better relate to the dataset, we visualize the samples below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "GoZpHlboDiL0"
      },
      "outputs": [],
      "source": [
        "def visualize_samples(data, label):\n",
        "    data_0 = data[label == 0]\n",
        "    data_1 = data[label == 1]\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "    plt.title(\"Dataset samples\")\n",
        "    plt.ylabel(r\"$x_2$\")\n",
        "    plt.xlabel(r\"$x_1$\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "EWa651SFDiL0",
        "outputId": "9a656a46-43f7-4d88-bb64-9b2f3a7b73ac"
      },
      "outputs": [
        {
          "data": {
            "application/pdf": "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",
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"283.789062pt\" height=\"285.283594pt\" viewBox=\"0 0 283.789062 285.283594\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
              " <metadata>\n",
              "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
              "   <cc:Work>\n",
              "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
              "    <dc:date>2024-01-05T17:11:30.269779</dc:date>\n",
              "    <dc:format>image/svg+xml</dc:format>\n",
              "    <dc:creator>\n",
              "     <cc:Agent>\n",
              "      <dc:title>Matplotlib v3.8.2, https://matplotlib.org/</dc:title>\n",
              "     </cc:Agent>\n",
              "    </dc:creator>\n",
              "   </cc:Work>\n",
              "  </rdf:RDF>\n",
              " </metadata>\n",
              " <defs>\n",
              "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
              " </defs>\n",
              " <g id=\"figure_1\">\n",
              "  <g id=\"patch_1\">\n",
              "   <path d=\"M 0 285.283594 \n",
              "L 283.789062 285.283594 \n",
              "L 283.789062 0 \n",
              "L 0 0 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "  </g>\n",
              "  <g id=\"axes_1\">\n",
              "   <g id=\"patch_2\">\n",
              "    <path d=\"M 53.389062 243.549375 \n",
              "L 276.589063 243.549375 \n",
              "L 276.589063 21.789375 \n",
              "L 53.389062 21.789375 \n",
              "z\n",
              "\" style=\"fill: #eaeaf2\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_1\">\n",
              "    <g id=\"xtick_1\">\n",
              "     <g id=\"line2d_1\">\n",
              "      <path d=\"M 92.702913 243.549375 \n",
              "L 92.702913 21.789375 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_1\">\n",
              "      <!-- 0.0 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(85.057913 260.922969) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
              "Q 266 3072 433 3567 \n",
              "Q 600 4063 929 4331 \n",
              "Q 1259 4600 1759 4600 \n",
              "Q 2128 4600 2406 4451 \n",
              "Q 2684 4303 2865 4023 \n",
              "Q 3047 3744 3150 3342 \n",
              "Q 3253 2941 3253 2259 \n",
              "Q 3253 1453 3087 958 \n",
              "Q 2922 463 2592 192 \n",
              "Q 2263 -78 1759 -78 \n",
              "Q 1097 -78 719 397 \n",
              "Q 266 969 266 2259 \n",
              "z\n",
              "M 844 2259 \n",
              "Q 844 1131 1108 757 \n",
              "Q 1372 384 1759 384 \n",
              "Q 2147 384 2411 759 \n",
              "Q 2675 1134 2675 2259 \n",
              "Q 2675 3391 2411 3762 \n",
              "Q 2147 4134 1753 4134 \n",
              "Q 1366 4134 1134 3806 \n",
              "Q 844 3388 844 2259 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "        <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
              "L 581 641 \n",
              "L 1222 641 \n",
              "L 1222 0 \n",
              "L 581 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_2\">\n",
              "     <g id=\"line2d_2\">\n",
              "      <path d=\"M 163.245145 243.549375 \n",
              "L 163.245145 21.789375 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_2\">\n",
              "      <!-- 0.5 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(155.600145 260.922969) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
              "L 856 1250 \n",
              "Q 922 819 1161 601 \n",
              "Q 1400 384 1738 384 \n",
              "Q 2144 384 2425 690 \n",
              "Q 2706 997 2706 1503 \n",
              "Q 2706 1984 2436 2262 \n",
              "Q 2166 2541 1728 2541 \n",
              "Q 1456 2541 1237 2417 \n",
              "Q 1019 2294 894 2097 \n",
              "L 366 2166 \n",
              "L 809 4519 \n",
              "L 3088 4519 \n",
              "L 3088 3981 \n",
              "L 1259 3981 \n",
              "L 1013 2750 \n",
              "Q 1425 3038 1878 3038 \n",
              "Q 2478 3038 2890 2622 \n",
              "Q 3303 2206 3303 1553 \n",
              "Q 3303 931 2941 478 \n",
              "Q 2500 -78 1738 -78 \n",
              "Q 1113 -78 717 272 \n",
              "Q 322 622 266 1200 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_3\">\n",
              "     <g id=\"line2d_3\">\n",
              "      <path d=\"M 233.787377 243.549375 \n",
              "L 233.787377 21.789375 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_3\">\n",
              "      <!-- 1.0 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(226.142377 260.922969) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
              "L 1822 0 \n",
              "L 1822 3584 \n",
              "Q 1619 3391 1289 3197 \n",
              "Q 959 3003 697 2906 \n",
              "L 697 3450 \n",
              "Q 1169 3672 1522 3987 \n",
              "Q 1875 4303 2022 4600 \n",
              "L 2384 4600 \n",
              "L 2384 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_4\">\n",
              "     <!-- $x_1$ -->\n",
              "     <g style=\"fill: #262626\" transform=\"translate(158.569063 275.698594) scale(0.12 -0.12)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-Oblique-78\" d=\"M 3841 3500 \n",
              "L 2234 1784 \n",
              "L 3219 0 \n",
              "L 2559 0 \n",
              "L 1819 1388 \n",
              "L 531 0 \n",
              "L -166 0 \n",
              "L 1556 1844 \n",
              "L 641 3500 \n",
              "L 1300 3500 \n",
              "L 1972 2234 \n",
              "L 3144 3500 \n",
              "L 3841 3500 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
              "L 1825 531 \n",
              "L 1825 4091 \n",
              "L 703 3866 \n",
              "L 703 4441 \n",
              "L 1819 4666 \n",
              "L 2450 4666 \n",
              "L 2450 531 \n",
              "L 3481 531 \n",
              "L 3481 0 \n",
              "L 794 0 \n",
              "L 794 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(59.179688 -16.09375) scale(0.7)\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_2\">\n",
              "    <g id=\"ytick_1\">\n",
              "     <g id=\"line2d_4\">\n",
              "      <path d=\"M 53.389062 234.1277 \n",
              "L 276.589063 234.1277 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_5\">\n",
              "      <!-- −0.2 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(22.174375 238.064497) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-2212\" d=\"M 3381 1997 \n",
              "L 356 1997 \n",
              "L 356 2522 \n",
              "L 3381 2522 \n",
              "L 3381 1997 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
              "L 3222 0 \n",
              "L 194 0 \n",
              "Q 188 203 259 391 \n",
              "Q 375 700 629 1000 \n",
              "Q 884 1300 1366 1694 \n",
              "Q 2113 2306 2375 2664 \n",
              "Q 2638 3022 2638 3341 \n",
              "Q 2638 3675 2398 3904 \n",
              "Q 2159 4134 1775 4134 \n",
              "Q 1369 4134 1125 3890 \n",
              "Q 881 3647 878 3216 \n",
              "L 300 3275 \n",
              "Q 359 3922 746 4261 \n",
              "Q 1134 4600 1788 4600 \n",
              "Q 2447 4600 2831 4234 \n",
              "Q 3216 3869 3216 3328 \n",
              "Q 3216 3053 3103 2787 \n",
              "Q 2991 2522 2730 2228 \n",
              "Q 2469 1934 1863 1422 \n",
              "Q 1356 997 1212 845 \n",
              "Q 1069 694 975 541 \n",
              "L 3222 541 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-2212\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"58.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"114.013672\"/>\n",
              "       <use xlink:href=\"#ArialMT-32\" x=\"141.796875\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_2\">\n",
              "     <g id=\"line2d_5\">\n",
              "      <path d=\"M 53.389062 206.647265 \n",
              "L 276.589063 206.647265 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_6\">\n",
              "      <!-- 0.0 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 210.584061) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_3\">\n",
              "     <g id=\"line2d_6\">\n",
              "      <path d=\"M 53.389062 179.166829 \n",
              "L 276.589063 179.166829 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_7\">\n",
              "      <!-- 0.2 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 183.103626) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_4\">\n",
              "     <g id=\"line2d_7\">\n",
              "      <path d=\"M 53.389062 151.686394 \n",
              "L 276.589063 151.686394 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_8\">\n",
              "      <!-- 0.4 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 155.62319) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
              "L 2069 1097 \n",
              "L 81 1097 \n",
              "L 81 1613 \n",
              "L 2172 4581 \n",
              "L 2631 4581 \n",
              "L 2631 1613 \n",
              "L 3250 1613 \n",
              "L 3250 1097 \n",
              "L 2631 1097 \n",
              "L 2631 0 \n",
              "L 2069 0 \n",
              "z\n",
              "M 2069 1613 \n",
              "L 2069 3678 \n",
              "L 634 1613 \n",
              "L 2069 1613 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_5\">\n",
              "     <g id=\"line2d_8\">\n",
              "      <path d=\"M 53.389062 124.205958 \n",
              "L 276.589063 124.205958 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_9\">\n",
              "      <!-- 0.6 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 128.142755) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
              "L 2625 3416 \n",
              "Q 2550 3747 2413 3897 \n",
              "Q 2184 4138 1850 4138 \n",
              "Q 1581 4138 1378 3988 \n",
              "Q 1113 3794 959 3422 \n",
              "Q 806 3050 800 2363 \n",
              "Q 1003 2672 1297 2822 \n",
              "Q 1591 2972 1913 2972 \n",
              "Q 2475 2972 2870 2558 \n",
              "Q 3266 2144 3266 1488 \n",
              "Q 3266 1056 3080 686 \n",
              "Q 2894 316 2569 119 \n",
              "Q 2244 -78 1831 -78 \n",
              "Q 1128 -78 684 439 \n",
              "Q 241 956 241 2144 \n",
              "Q 241 3472 731 4075 \n",
              "Q 1159 4600 1884 4600 \n",
              "Q 2425 4600 2770 4297 \n",
              "Q 3116 3994 3184 3459 \n",
              "z\n",
              "M 888 1484 \n",
              "Q 888 1194 1011 928 \n",
              "Q 1134 663 1356 523 \n",
              "Q 1578 384 1822 384 \n",
              "Q 2178 384 2434 671 \n",
              "Q 2691 959 2691 1453 \n",
              "Q 2691 1928 2437 2201 \n",
              "Q 2184 2475 1800 2475 \n",
              "Q 1419 2475 1153 2201 \n",
              "Q 888 1928 888 1484 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_6\">\n",
              "     <g id=\"line2d_9\">\n",
              "      <path d=\"M 53.389062 96.725523 \n",
              "L 276.589063 96.725523 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_10\">\n",
              "      <!-- 0.8 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 100.662319) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
              "Q 781 2613 612 2850 \n",
              "Q 444 3088 444 3419 \n",
              "Q 444 3919 803 4259 \n",
              "Q 1163 4600 1759 4600 \n",
              "Q 2359 4600 2725 4251 \n",
              "Q 3091 3903 3091 3403 \n",
              "Q 3091 3084 2923 2848 \n",
              "Q 2756 2613 2416 2484 \n",
              "Q 2838 2347 3058 2040 \n",
              "Q 3278 1734 3278 1309 \n",
              "Q 3278 722 2862 322 \n",
              "Q 2447 -78 1769 -78 \n",
              "Q 1091 -78 675 323 \n",
              "Q 259 725 259 1325 \n",
              "Q 259 1772 486 2073 \n",
              "Q 713 2375 1131 2484 \n",
              "z\n",
              "M 1019 3438 \n",
              "Q 1019 3113 1228 2906 \n",
              "Q 1438 2700 1772 2700 \n",
              "Q 2097 2700 2305 2904 \n",
              "Q 2513 3109 2513 3406 \n",
              "Q 2513 3716 2298 3927 \n",
              "Q 2084 4138 1766 4138 \n",
              "Q 1444 4138 1231 3931 \n",
              "Q 1019 3725 1019 3438 \n",
              "z\n",
              "M 838 1322 \n",
              "Q 838 1081 952 856 \n",
              "Q 1066 631 1291 507 \n",
              "Q 1516 384 1775 384 \n",
              "Q 2178 384 2440 643 \n",
              "Q 2703 903 2703 1303 \n",
              "Q 2703 1709 2433 1975 \n",
              "Q 2163 2241 1756 2241 \n",
              "Q 1359 2241 1098 1978 \n",
              "Q 838 1716 838 1322 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_7\">\n",
              "     <g id=\"line2d_10\">\n",
              "      <path d=\"M 53.389062 69.245087 \n",
              "L 276.589063 69.245087 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_11\">\n",
              "      <!-- 1.0 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 73.181884) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_8\">\n",
              "     <g id=\"line2d_11\">\n",
              "      <path d=\"M 53.389062 41.764652 \n",
              "L 276.589063 41.764652 \n",
              "\" clip-path=\"url(#p9712abc74c)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"text_12\">\n",
              "      <!-- 1.2 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 45.701448) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_13\">\n",
              "     <!-- $x_2$ -->\n",
              "     <g style=\"fill: #262626\" transform=\"translate(15.789375 139.089375) rotate(-90) scale(0.12 -0.12)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
              "L 3431 531 \n",
              "L 3431 0 \n",
              "L 469 0 \n",
              "L 469 531 \n",
              "Q 828 903 1448 1529 \n",
              "Q 2069 2156 2228 2338 \n",
              "Q 2531 2678 2651 2914 \n",
              "Q 2772 3150 2772 3378 \n",
              "Q 2772 3750 2511 3984 \n",
              "Q 2250 4219 1831 4219 \n",
              "Q 1534 4219 1204 4116 \n",
              "Q 875 4013 500 3803 \n",
              "L 500 4441 \n",
              "Q 881 4594 1212 4672 \n",
              "Q 1544 4750 1819 4750 \n",
              "Q 2544 4750 2975 4387 \n",
              "Q 3406 4025 3406 3419 \n",
              "Q 3406 3131 3298 2873 \n",
              "Q 3191 2616 2906 2266 \n",
              "Q 2828 2175 2409 1742 \n",
              "Q 1991 1309 1228 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(59.179688 -16.09375) scale(0.7)\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"PathCollection_1\">\n",
              "    <defs>\n",
              "     <path id=\"m43b4a4e432\" d=\"M 0 3 \n",
              "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
              "C 2.683901 1.55874 3 0.795609 3 0 \n",
              "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
              "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
              "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
              "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
              "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
              "C -1.55874 2.683901 -0.795609 3 0 3 \n",
              "z\n",
              "\" style=\"stroke: #333333\"/>\n",
              "    </defs>\n",
              "    <g clip-path=\"url(#p9712abc74c)\">\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"96.83771\" y=\"216.462608\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"75.895471\" y=\"197.626075\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"109.048897\" y=\"217.923619\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"106.294654\" y=\"200.975565\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"230.325332\" y=\"79.601582\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"237.691053\" y=\"57.879403\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"233.970817\" y=\"49.273208\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"230.053485\" y=\"31.869375\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"242.614575\" y=\"81.022621\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"77.594283\" y=\"200.017989\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"230.634667\" y=\"59.434565\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"86.403281\" y=\"194.880159\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"95.723443\" y=\"223.763987\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"236.230696\" y=\"63.950737\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"221.31752\" y=\"67.13287\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"238.835205\" y=\"61.539788\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"100.757291\" y=\"191.044345\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"106.162396\" y=\"197.697007\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"88.254954\" y=\"196.218863\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"266.443608\" y=\"94.901716\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"243.469446\" y=\"91.404152\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"223.695557\" y=\"59.907265\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"64.131297\" y=\"204.085342\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"222.606142\" y=\"70.821592\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"240.911963\" y=\"57.349424\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"216.853061\" y=\"73.841207\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"227.086637\" y=\"78.221977\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"258.695188\" y=\"63.680555\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"212.351426\" y=\"75.898569\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"251.661524\" y=\"78.968617\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"240.048985\" y=\"58.601449\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"230.224033\" y=\"86.389901\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"235.388926\" y=\"60.147275\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"122.796701\" y=\"233.469375\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"90.561461\" y=\"198.563658\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"96.667272\" y=\"215.203292\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"89.766631\" y=\"213.421205\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"238.824306\" y=\"78.765813\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"104.171135\" y=\"197.996027\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"103.246065\" y=\"198.260644\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"92.408024\" y=\"205.035161\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"104.348256\" y=\"195.469464\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"252.205655\" y=\"68.956495\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"250.126526\" y=\"58.367466\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"101.508274\" y=\"198.01366\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"92.53013\" y=\"218.975735\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"93.772398\" y=\"215.951614\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"81.05643\" y=\"211.063176\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"96.159011\" y=\"213.612774\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"86.057294\" y=\"203.458848\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"223.651249\" y=\"72.177898\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"97.089336\" y=\"186.375549\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"92.434624\" y=\"220.422236\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"238.340436\" y=\"80.611418\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"91.168476\" y=\"201.127658\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"102.439773\" y=\"212.160121\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"95.86451\" y=\"206.474242\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"113.176295\" y=\"193.466675\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"264.165431\" y=\"79.788613\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"246.094473\" y=\"66.725935\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"80.855742\" y=\"214.88305\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"203.822506\" y=\"76.469079\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"223.077197\" y=\"67.178651\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"238.609028\" y=\"43.466094\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"247.196376\" y=\"77.171871\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"91.086934\" y=\"189.639399\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"70.208016\" y=\"214.882808\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"77.640447\" y=\"208.60359\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"97.391347\" y=\"216.931632\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"250.425425\" y=\"68.317362\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"121.776864\" y=\"182.528499\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"230.274876\" y=\"55.895487\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"242.892636\" y=\"50.439797\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"229.986463\" y=\"59.385901\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"68.670833\" y=\"207.410502\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"63.534517\" y=\"207.871793\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"238.959511\" y=\"82.159243\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"78.79585\" y=\"199.721555\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"225.976249\" y=\"85.704193\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"261.506598\" y=\"68.760562\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"85.218366\" y=\"214.559132\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"256.995317\" y=\"72.666895\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"241.9217\" y=\"64.968435\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"136.141139\" y=\"191.264062\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"231.98266\" y=\"82.374422\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"70.038451\" y=\"203.85163\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"224.665241\" y=\"84.105788\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"116.505861\" y=\"194.533342\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"233.674895\" y=\"48.910334\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"78.068981\" y=\"209.262559\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"234.471944\" y=\"80.662523\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"96.518639\" y=\"207.337547\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"99.770076\" y=\"220.079086\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"235.188802\" y=\"58.920868\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"69.150198\" y=\"199.181377\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"224.438787\" y=\"61.404935\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"223.018979\" y=\"94.044563\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"232.85509\" y=\"85.884713\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"106.900141\" y=\"214.573884\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"104.493231\" y=\"222.169683\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"100.177627\" y=\"186.839798\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"198.916316\" y=\"80.194598\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m43b4a4e432\" x=\"239.023674\" y=\"77.543975\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"PathCollection_2\">\n",
              "    <defs>\n",
              "     <path id=\"mf9a145d883\" d=\"M 0 3 \n",
              "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
              "C 2.683901 1.55874 3 0.795609 3 0 \n",
              "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
              "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
              "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
              "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
              "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
              "C -1.55874 2.683901 -0.795609 3 0 3 \n",
              "z\n",
              "\" style=\"stroke: #333333\"/>\n",
              "    </defs>\n",
              "    <g clip-path=\"url(#p9712abc74c)\">\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"83.108821\" y=\"66.053863\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"119.026093\" y=\"62.734517\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"78.951669\" y=\"58.43038\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"245.385368\" y=\"180.584916\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"221.237707\" y=\"217.856675\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"232.699594\" y=\"201.959762\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"240.464017\" y=\"207.64795\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"221.840434\" y=\"227.461596\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"234.608612\" y=\"222.351926\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"107.983084\" y=\"54.765621\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"73.266138\" y=\"82.131005\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"99.969261\" y=\"62.185554\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"241.053895\" y=\"153.709894\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"81.79955\" y=\"72.499029\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"226.939651\" y=\"205.522296\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"86.044687\" y=\"54.282668\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"93.609804\" y=\"84.053537\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"82.398574\" y=\"66.270893\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"93.345861\" y=\"78.198218\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"122.950633\" y=\"60.534899\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"224.450602\" y=\"194.934644\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"215.998266\" y=\"194.035641\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"122.64324\" y=\"55.058784\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"220.709831\" y=\"207.465156\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"188.058133\" y=\"220.722574\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"115.733701\" y=\"88.89554\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"86.494569\" y=\"67.448685\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"254.12151\" y=\"226.376324\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"250.197803\" y=\"206.50666\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"219.939817\" y=\"200.297862\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"95.511336\" y=\"77.492199\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"234.772172\" y=\"211.941557\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"256.163605\" y=\"223.655119\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"225.472356\" y=\"194.973547\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"246.479333\" y=\"202.424902\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"81.007081\" y=\"76.942098\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"110.72878\" y=\"77.373406\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"100.421607\" y=\"72.023258\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"89.631769\" y=\"54.147651\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"243.408681\" y=\"210.910397\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"238.360853\" y=\"208.435458\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"94.071375\" y=\"61.067498\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"222.24355\" y=\"177.897408\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"78.50957\" y=\"85.928299\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"247.544806\" y=\"208.667865\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"239.613198\" y=\"214.392963\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"81.102661\" y=\"65.896766\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"72.272692\" y=\"88.583943\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"104.803158\" y=\"71.442675\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"233.526185\" y=\"210.613497\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"241.114542\" y=\"185.587098\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"235.165441\" y=\"217.268588\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"234.133184\" y=\"199.804659\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"123.597631\" y=\"80.351277\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"80.027677\" y=\"62.486006\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"215.160936\" y=\"181.482622\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"250.427444\" y=\"213.09384\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"68.533247\" y=\"50.642593\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"233.861362\" y=\"206.001741\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"227.437649\" y=\"198.089171\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"94.400097\" y=\"62.176578\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"243.827161\" y=\"222.100092\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"71.058945\" y=\"51.689529\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"114.587258\" y=\"67.655691\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"79.089343\" y=\"59.818585\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"107.635638\" y=\"93.410549\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"76.008974\" y=\"97.264582\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"254.983294\" y=\"205.629186\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"256.764617\" y=\"225.610159\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"98.12148\" y=\"69.694323\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"74.298874\" y=\"60.043641\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"226.53751\" y=\"221.201089\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"91.818608\" y=\"56.121231\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"85.221802\" y=\"80.139333\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"232.277346\" y=\"220.871719\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"223.915334\" y=\"203.707134\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"232.202605\" y=\"209.683435\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"101.367851\" y=\"58.836758\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"88.822361\" y=\"100.873986\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"212.410383\" y=\"187.866114\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"223.116443\" y=\"226.18934\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"93.79446\" y=\"81.079319\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"114.191828\" y=\"61.840338\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"80.3493\" y=\"88.245057\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"246.854303\" y=\"180.411464\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"214.055762\" y=\"198.911945\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"83.523357\" y=\"75.938298\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"225.42962\" y=\"218.518686\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"230.416194\" y=\"219.117387\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"84.565565\" y=\"58.865849\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"69.740819\" y=\"68.584382\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"237.451658\" y=\"219.072772\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"242.796922\" y=\"229.476911\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"224.590978\" y=\"205.995996\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"80.563817\" y=\"74.528963\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"100.844504\" y=\"72.034978\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#mf9a145d883\" x=\"235.009028\" y=\"208.786304\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"patch_3\">\n",
              "    <path d=\"M 53.389062 243.549375 \n",
              "L 53.389062 21.789375 \n",
              "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_4\">\n",
              "    <path d=\"M 276.589063 243.549375 \n",
              "L 276.589063 21.789375 \n",
              "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_5\">\n",
              "    <path d=\"M 53.389062 243.549375 \n",
              "L 276.589063 243.549375 \n",
              "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_6\">\n",
              "    <path d=\"M 53.389062 21.789375 \n",
              "L 276.589063 21.789375 \n",
              "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"text_14\">\n",
              "    <!-- Dataset samples -->\n",
              "    <g style=\"fill: #262626\" transform=\"translate(120.305 15.789375) scale(0.12 -0.12)\">\n",
              "     <defs>\n",
              "      <path id=\"ArialMT-44\" d=\"M 494 0 \n",
              "L 494 4581 \n",
              "L 2072 4581 \n",
              "Q 2606 4581 2888 4516 \n",
              "Q 3281 4425 3559 4188 \n",
              "Q 3922 3881 4101 3404 \n",
              "Q 4281 2928 4281 2316 \n",
              "Q 4281 1794 4159 1391 \n",
              "Q 4038 988 3847 723 \n",
              "Q 3656 459 3429 307 \n",
              "Q 3203 156 2883 78 \n",
              "Q 2563 0 2147 0 \n",
              "L 494 0 \n",
              "z\n",
              "M 1100 541 \n",
              "L 2078 541 \n",
              "Q 2531 541 2789 625 \n",
              "Q 3047 709 3200 863 \n",
              "Q 3416 1078 3536 1442 \n",
              "Q 3656 1806 3656 2325 \n",
              "Q 3656 3044 3420 3430 \n",
              "Q 3184 3816 2847 3947 \n",
              "Q 2603 4041 2063 4041 \n",
              "L 1100 4041 \n",
              "L 1100 541 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
              "Q 2275 144 1986 34 \n",
              "Q 1697 -75 1366 -75 \n",
              "Q 819 -75 525 192 \n",
              "Q 231 459 231 875 \n",
              "Q 231 1119 342 1320 \n",
              "Q 453 1522 633 1644 \n",
              "Q 813 1766 1038 1828 \n",
              "Q 1203 1872 1538 1913 \n",
              "Q 2219 1994 2541 2106 \n",
              "Q 2544 2222 2544 2253 \n",
              "Q 2544 2597 2384 2738 \n",
              "Q 2169 2928 1744 2928 \n",
              "Q 1347 2928 1158 2789 \n",
              "Q 969 2650 878 2297 \n",
              "L 328 2372 \n",
              "Q 403 2725 575 2942 \n",
              "Q 747 3159 1072 3276 \n",
              "Q 1397 3394 1825 3394 \n",
              "Q 2250 3394 2515 3294 \n",
              "Q 2781 3194 2906 3042 \n",
              "Q 3031 2891 3081 2659 \n",
              "Q 3109 2516 3109 2141 \n",
              "L 3109 1391 \n",
              "Q 3109 606 3145 398 \n",
              "Q 3181 191 3288 0 \n",
              "L 2700 0 \n",
              "Q 2613 175 2588 409 \n",
              "z\n",
              "M 2541 1666 \n",
              "Q 2234 1541 1622 1453 \n",
              "Q 1275 1403 1131 1340 \n",
              "Q 988 1278 909 1158 \n",
              "Q 831 1038 831 891 \n",
              "Q 831 666 1001 516 \n",
              "Q 1172 366 1500 366 \n",
              "Q 1825 366 2078 508 \n",
              "Q 2331 650 2450 897 \n",
              "Q 2541 1088 2541 1459 \n",
              "L 2541 1666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
              "L 1731 6 \n",
              "Q 1494 -44 1306 -44 \n",
              "Q 1000 -44 831 53 \n",
              "Q 663 150 594 308 \n",
              "Q 525 466 525 972 \n",
              "L 525 2881 \n",
              "L 113 2881 \n",
              "L 113 3319 \n",
              "L 525 3319 \n",
              "L 525 4141 \n",
              "L 1084 4478 \n",
              "L 1084 3319 \n",
              "L 1650 3319 \n",
              "L 1650 2881 \n",
              "L 1084 2881 \n",
              "L 1084 941 \n",
              "Q 1084 700 1114 631 \n",
              "Q 1144 563 1211 522 \n",
              "Q 1278 481 1403 481 \n",
              "Q 1497 481 1650 503 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-73\" d=\"M 197 991 \n",
              "L 753 1078 \n",
              "Q 800 744 1014 566 \n",
              "Q 1228 388 1613 388 \n",
              "Q 2000 388 2187 545 \n",
              "Q 2375 703 2375 916 \n",
              "Q 2375 1106 2209 1216 \n",
              "Q 2094 1291 1634 1406 \n",
              "Q 1016 1563 777 1677 \n",
              "Q 538 1791 414 1992 \n",
              "Q 291 2194 291 2438 \n",
              "Q 291 2659 392 2848 \n",
              "Q 494 3038 669 3163 \n",
              "Q 800 3259 1026 3326 \n",
              "Q 1253 3394 1513 3394 \n",
              "Q 1903 3394 2198 3281 \n",
              "Q 2494 3169 2634 2976 \n",
              "Q 2775 2784 2828 2463 \n",
              "L 2278 2388 \n",
              "Q 2241 2644 2061 2787 \n",
              "Q 1881 2931 1553 2931 \n",
              "Q 1166 2931 1000 2803 \n",
              "Q 834 2675 834 2503 \n",
              "Q 834 2394 903 2306 \n",
              "Q 972 2216 1119 2156 \n",
              "Q 1203 2125 1616 2013 \n",
              "Q 2213 1853 2448 1751 \n",
              "Q 2684 1650 2818 1456 \n",
              "Q 2953 1263 2953 975 \n",
              "Q 2953 694 2789 445 \n",
              "Q 2625 197 2315 61 \n",
              "Q 2006 -75 1616 -75 \n",
              "Q 969 -75 630 194 \n",
              "Q 291 463 197 991 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
              "L 3275 997 \n",
              "Q 3138 488 2766 206 \n",
              "Q 2394 -75 1816 -75 \n",
              "Q 1088 -75 661 373 \n",
              "Q 234 822 234 1631 \n",
              "Q 234 2469 665 2931 \n",
              "Q 1097 3394 1784 3394 \n",
              "Q 2450 3394 2872 2941 \n",
              "Q 3294 2488 3294 1666 \n",
              "Q 3294 1616 3291 1516 \n",
              "L 816 1516 \n",
              "Q 847 969 1125 678 \n",
              "Q 1403 388 1819 388 \n",
              "Q 2128 388 2347 550 \n",
              "Q 2566 713 2694 1069 \n",
              "z\n",
              "M 847 1978 \n",
              "L 2700 1978 \n",
              "Q 2663 2397 2488 2606 \n",
              "Q 2219 2931 1791 2931 \n",
              "Q 1403 2931 1139 2672 \n",
              "Q 875 2413 847 1978 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
              "L 422 3319 \n",
              "L 925 3319 \n",
              "L 925 2853 \n",
              "Q 1081 3097 1340 3245 \n",
              "Q 1600 3394 1931 3394 \n",
              "Q 2300 3394 2536 3241 \n",
              "Q 2772 3088 2869 2813 \n",
              "Q 3263 3394 3894 3394 \n",
              "Q 4388 3394 4653 3120 \n",
              "Q 4919 2847 4919 2278 \n",
              "L 4919 0 \n",
              "L 4359 0 \n",
              "L 4359 2091 \n",
              "Q 4359 2428 4304 2576 \n",
              "Q 4250 2725 4106 2815 \n",
              "Q 3963 2906 3769 2906 \n",
              "Q 3419 2906 3187 2673 \n",
              "Q 2956 2441 2956 1928 \n",
              "L 2956 0 \n",
              "L 2394 0 \n",
              "L 2394 2156 \n",
              "Q 2394 2531 2256 2718 \n",
              "Q 2119 2906 1806 2906 \n",
              "Q 1569 2906 1367 2781 \n",
              "Q 1166 2656 1075 2415 \n",
              "Q 984 2175 984 1722 \n",
              "L 984 0 \n",
              "L 422 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
              "L 422 3319 \n",
              "L 934 3319 \n",
              "L 934 2888 \n",
              "Q 1116 3141 1344 3267 \n",
              "Q 1572 3394 1897 3394 \n",
              "Q 2322 3394 2647 3175 \n",
              "Q 2972 2956 3137 2557 \n",
              "Q 3303 2159 3303 1684 \n",
              "Q 3303 1175 3120 767 \n",
              "Q 2938 359 2589 142 \n",
              "Q 2241 -75 1856 -75 \n",
              "Q 1575 -75 1351 44 \n",
              "Q 1128 163 984 344 \n",
              "L 984 -1272 \n",
              "L 422 -1272 \n",
              "z\n",
              "M 931 1641 \n",
              "Q 931 1000 1190 694 \n",
              "Q 1450 388 1819 388 \n",
              "Q 2194 388 2461 705 \n",
              "Q 2728 1022 2728 1688 \n",
              "Q 2728 2322 2467 2637 \n",
              "Q 2206 2953 1844 2953 \n",
              "Q 1484 2953 1207 2617 \n",
              "Q 931 2281 931 1641 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
              "L 409 4581 \n",
              "L 972 4581 \n",
              "L 972 0 \n",
              "L 409 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "     </defs>\n",
              "     <use xlink:href=\"#ArialMT-44\"/>\n",
              "     <use xlink:href=\"#ArialMT-61\" x=\"72.216797\"/>\n",
              "     <use xlink:href=\"#ArialMT-74\" x=\"127.832031\"/>\n",
              "     <use xlink:href=\"#ArialMT-61\" x=\"155.615234\"/>\n",
              "     <use xlink:href=\"#ArialMT-73\" x=\"211.230469\"/>\n",
              "     <use xlink:href=\"#ArialMT-65\" x=\"261.230469\"/>\n",
              "     <use xlink:href=\"#ArialMT-74\" x=\"316.845703\"/>\n",
              "     <use xlink:href=\"#ArialMT-20\" x=\"344.628906\"/>\n",
              "     <use xlink:href=\"#ArialMT-73\" x=\"372.412109\"/>\n",
              "     <use xlink:href=\"#ArialMT-61\" x=\"422.412109\"/>\n",
              "     <use xlink:href=\"#ArialMT-6d\" x=\"478.027344\"/>\n",
              "     <use xlink:href=\"#ArialMT-70\" x=\"561.328125\"/>\n",
              "     <use xlink:href=\"#ArialMT-6c\" x=\"616.943359\"/>\n",
              "     <use xlink:href=\"#ArialMT-65\" x=\"639.160156\"/>\n",
              "     <use xlink:href=\"#ArialMT-73\" x=\"694.775391\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"legend_1\">\n",
              "    <g id=\"patch_7\">\n",
              "     <path d=\"M 197.010937 149.879219 \n",
              "L 268.889063 149.879219 \n",
              "Q 271.089063 149.879219 271.089063 147.679219 \n",
              "L 271.089063 117.659531 \n",
              "Q 271.089063 115.459531 268.889063 115.459531 \n",
              "L 197.010937 115.459531 \n",
              "Q 194.810937 115.459531 194.810937 117.659531 \n",
              "L 194.810937 147.679219 \n",
              "Q 194.810937 149.879219 197.010937 149.879219 \n",
              "z\n",
              "\" style=\"fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"PathCollection_3\">\n",
              "     <g>\n",
              "      <use xlink:href=\"#m43b4a4e432\" x=\"210.210938\" y=\"124.845625\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_15\">\n",
              "     <!-- Class 0 -->\n",
              "     <g style=\"fill: #262626\" transform=\"translate(230.010938 127.733125) scale(0.11 -0.11)\">\n",
              "      <defs>\n",
              "       <path id=\"ArialMT-43\" d=\"M 3763 1606 \n",
              "L 4369 1453 \n",
              "Q 4178 706 3683 314 \n",
              "Q 3188 -78 2472 -78 \n",
              "Q 1731 -78 1267 223 \n",
              "Q 803 525 561 1097 \n",
              "Q 319 1669 319 2325 \n",
              "Q 319 3041 592 3573 \n",
              "Q 866 4106 1370 4382 \n",
              "Q 1875 4659 2481 4659 \n",
              "Q 3169 4659 3637 4309 \n",
              "Q 4106 3959 4291 3325 \n",
              "L 3694 3184 \n",
              "Q 3534 3684 3231 3912 \n",
              "Q 2928 4141 2469 4141 \n",
              "Q 1941 4141 1586 3887 \n",
              "Q 1231 3634 1087 3207 \n",
              "Q 944 2781 944 2328 \n",
              "Q 944 1744 1114 1308 \n",
              "Q 1284 872 1643 656 \n",
              "Q 2003 441 2422 441 \n",
              "Q 2931 441 3284 734 \n",
              "Q 3638 1028 3763 1606 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#ArialMT-43\"/>\n",
              "      <use xlink:href=\"#ArialMT-6c\" x=\"72.216797\"/>\n",
              "      <use xlink:href=\"#ArialMT-61\" x=\"94.433594\"/>\n",
              "      <use xlink:href=\"#ArialMT-73\" x=\"150.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-73\" x=\"200.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-20\" x=\"250.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-30\" x=\"277.832031\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"PathCollection_4\">\n",
              "     <g>\n",
              "      <use xlink:href=\"#mf9a145d883\" x=\"210.210938\" y=\"140.405469\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_16\">\n",
              "     <!-- Class 1 -->\n",
              "     <g style=\"fill: #262626\" transform=\"translate(230.010938 143.292969) scale(0.11 -0.11)\">\n",
              "      <use xlink:href=\"#ArialMT-43\"/>\n",
              "      <use xlink:href=\"#ArialMT-6c\" x=\"72.216797\"/>\n",
              "      <use xlink:href=\"#ArialMT-61\" x=\"94.433594\"/>\n",
              "      <use xlink:href=\"#ArialMT-73\" x=\"150.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-73\" x=\"200.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-20\" x=\"250.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-31\" x=\"277.832031\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              " </g>\n",
              " <defs>\n",
              "  <clipPath id=\"p9712abc74c\">\n",
              "   <rect x=\"53.389062\" y=\"21.789375\" width=\"223.2\" height=\"221.76\"/>\n",
              "  </clipPath>\n",
              " </defs>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize_samples(dataset.data, dataset.label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my05Ok_IDiL0"
      },
      "source": [
        "#### The data loader class\n",
        "\n",
        "The class `torch.utils.data.DataLoader` represents a Python iterable over a dataset with support for automatic batching, multi-process data loading and many more features. The data loader communicates with the dataset using the function `__getitem__`, and stacks its outputs as tensors over the first dimension to form a batch.\n",
        "In contrast to the dataset class, we usually don't have to define our own data loader class, but can just create an object of it with the dataset as input. Additionally, we can configure our data loader with the following input arguments (only a selection, see full list [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n",
        "\n",
        "* `batch_size`: Number of samples to stack per batch\n",
        "* `shuffle`: If True, the data is returned in a random order. This is important during training for introducing stochasticity.\n",
        "* `num_workers`: Number of subprocesses to use for data loading. The default, 0, means that the data will be loaded in the main process which can slow down training for datasets where loading a data point takes a considerable amount of time (e.g. large images). More workers are recommended for those, but can cause issues on Windows computers. For tiny datasets as ours, 0 workers are usually faster.\n",
        "* `persistent_workers`: If True, workers will not be shutdown after an iteration over the dataset has finished. This can be useful if the time per epoch is small, or if you face issues with workers being killed during training.\n",
        "* `drop_last`: If True, the last batch is dropped in case it is smaller than the specified batch size. This occurs when the dataset size is not a multiple of the batch size. Only potentially helpful during training to keep a consistent batch size.\n",
        "* `collate_fn`: A function that defines how the elements per batch are combined. By default, PyTorch stacks them as PyTorch tensors. For JAX, we will change it to NumPy arrays.\n",
        "\n",
        "Let's create a simple data loader below with a function that stacks batch elements as NumPy array instead of PyTorch Tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "xYe2tYxWDiL0"
      },
      "outputs": [],
      "source": [
        "# This collate function is taken from the JAX tutorial with PyTorch Data Loading\n",
        "# https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html\n",
        "def numpy_collate(batch):\n",
        "    if isinstance(batch[0], np.ndarray):\n",
        "        return np.stack(batch)\n",
        "    elif isinstance(batch[0], (tuple,list)):\n",
        "        transposed = zip(*batch)\n",
        "        return [numpy_collate(samples) for samples in transposed]\n",
        "    else:\n",
        "        return np.array(batch)\n",
        "\n",
        "# data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=numpy_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "jUMqDlhKDiL0",
        "outputId": "686817a8-98dc-4d99-a3de-7e3bb0e85b27"
      },
      "outputs": [],
      "source": [
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "# data_inputs, data_labels = next(iter(data_loader))\n",
        "\n",
        "# # The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the\n",
        "# # dimensions of the data point returned from the dataset class\n",
        "# print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "# print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG8faUeADiL0"
      },
      "source": [
        "### Optimization\n",
        "\n",
        "After defining the model and the dataset, it is time to prepare the optimization of the model. During training, we will perform the following steps:\n",
        "\n",
        "1. Get a batch from the data loader\n",
        "2. Obtain the predictions from the model for the batch\n",
        "3. Calculate the loss based on the difference between predictions and labels\n",
        "4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n",
        "5. Update the parameters of the model in the direction of the gradients\n",
        "\n",
        "We have seen how we can do step 1, 2 and 4 in JAX and Flax. Now, we will look at step 3 and 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfL0akXnDiL0"
      },
      "source": [
        "#### Stochastic Gradient Descent\n",
        "\n",
        "For updating the parameters, Flax does not directly provide support for optimizers, but instead refers to another package called `optax` ([documentation](https://optax.readthedocs.io/en/latest/index.html)). Optax is an optimization library for JAX, which offers most common deep learning optimizers (SGD, Adam, Adagrad, RMSProp, etc.) and utilities (gradient clipping, weight decay, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "UExu7oe8DiL0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import optax\n",
        "except ModuleNotFoundError: # Install optax if missing\n",
        "    !pip install --quiet optax\n",
        "    import optax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjr1m1AqDiL0"
      },
      "source": [
        "For now, we will use the simplest optimizer, namely `optax.sgd`. Stochastic Gradient Descent updates parameters by multiplying the gradients with a small constant, called learning rate, and subtracting those from the parameters (hence minimizing the loss). Therefore, we slowly move towards the direction of minimizing the loss. A good default value of the learning rate for a small network as ours is 0.1. Remember that we again aim to write functional code. Hence, the optimizer does not take as input the parameters, but only the optimizer hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "OTp-IUSWDiL1"
      },
      "outputs": [],
      "source": [
        "# Input to the optimizer are optimizer settings like learning rate\n",
        "optimizer = optax.sgd(learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RIYHciBDiL1"
      },
      "source": [
        "Since JAX calculates gradients via function transformations, we do not have functions like `backward()`, `optimizer.step()` or `optimizer.backward()` as in PyTorch. Instead, a optimizer is a function on the parameters and gradients. To simplify this step and bundle important parts of the training procedure, Flax offers the `flax.training` package. As a first step, we can create a `TrainState` which bundles the parameters, the optimizer, and the forward step of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "7OjHPPvVDiL1"
      },
      "outputs": [],
      "source": [
        "from flax.training import train_state\n",
        "\n",
        "model_state = train_state.TrainState.create(apply_fn=model.apply,\n",
        "                                            params=params,\n",
        "                                            tx=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbxKC-peDiL1"
      },
      "source": [
        "With this state object, it is easier to handle the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZgP7mgBDiL1"
      },
      "source": [
        "#### Loss function\n",
        "\n",
        "For performing gradient updates, we need a function that can calculate the loss for a batch. Afterwards, we can apply JAX's gradient transformation to obtain a gradient function of it. In our setting, which is binary classification, we can use Binary Cross Entropy (BCE) which is defined as follows:\n",
        "\n",
        "$$\\mathcal{L}_{BCE} = -\\sum_i \\left[ y_i \\log x_i + (1 - y_i) \\log (1 - x_i) \\right]$$\n",
        "\n",
        "where $y$ are our labels, and $x$ our predictions, both in the range of $[0,1]$. Similar to PyTorch, Optax already provides a function for this: `optax.sigmoid_binary_cross_entropy(logits, labels)`. We calculate the loss on the logits instead of the sigmoid outputs for numerical stability. Let's write a function that takes as input a state (for the forward function), parameters, and a batch, and return the binary cross entropy loss and accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "aW7j8fnbDiL1"
      },
      "outputs": [],
      "source": [
        "def calculate_loss_acc(state, params, batch):\n",
        "    data_input, labels = batch\n",
        "    # Obtain the logits and predictions of the model for the input data\n",
        "    logits = state.apply_fn(params, data_input).squeeze(axis=-1)\n",
        "    pred_labels = (logits > 0).astype(jnp.float32)\n",
        "    # Calculate the loss and accuracy\n",
        "    loss = optax.sigmoid_binary_cross_entropy(logits, labels).mean()\n",
        "    acc = (pred_labels == labels).mean()\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JprcTyIsDiL1"
      },
      "source": [
        "Note that we explicitly add the parameters here as an input argument since we want to calculate the gradients with respect to them later. An example execution of the function would look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "NXU_04v-DiL1",
        "outputId": "2ecda7ad-392d-43d4-fad6-6f36a4f5a970"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Array(0.7517859, dtype=float32), Array(0.25, dtype=float32))"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# batch = next(iter(data_loader))\n",
        "# calculate_loss_acc(model_state, model_state.params, batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSU-EjrSDiL1"
      },
      "source": [
        "### Creating an efficient training and validation step\n",
        "\n",
        "With this loss function and the optimizer, we are now ready to create an efficient training and validation/test step. First, let's consider the training. As input to each training step, we have a training state and a batch. We then want to calculate the loss for the input and take the gradients of it. Finally, we update the parameters with our optimizer and return the new state. All this can be summarized in the following function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "mI2jJN67DiL1"
      },
      "outputs": [],
      "source": [
        "@jax.jit  # Jit the function for efficiency\n",
        "def train_step(state, batch):\n",
        "    # Gradient function\n",
        "    grad_fn = jax.value_and_grad(calculate_loss_acc,  # Function to calculate the loss\n",
        "                                 argnums=1,  # Parameters are second argument of the function\n",
        "                                 has_aux=True  # Function has additional outputs, here accuracy\n",
        "                                )\n",
        "    # Determine gradients for current model, parameters and batch\n",
        "    (loss, acc), grads = grad_fn(state, state.params, batch)\n",
        "    # Perform parameter update with gradients and optimizer\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    # Return state and any other value we might want\n",
        "    return state, loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XddS91GpDiL1"
      },
      "source": [
        "By using the transformation `jax.jit`, the whole gradient calculation and application is optimized in XLA, providing an efficient function for updating the model.\n",
        "\n",
        "Next, let's look at the evaluation function. Here, we do not need to calculate gradients, but only want to get the accuracy of the model for the batch. This becomes a simpler version of the training step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "U1mn5FD9DiL1"
      },
      "outputs": [],
      "source": [
        "@jax.jit  # Jit the function for efficiency\n",
        "def eval_step(state, batch):\n",
        "    # Determine the accuracy\n",
        "    _, acc = calculate_loss_acc(state, state.params, batch)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQtLqxaODiL1"
      },
      "source": [
        "These two functions provide us now efficient utilities to train our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t65SykEnDiL1"
      },
      "source": [
        "### Training\n",
        "\n",
        "Finally, we are ready to train our model. As a first step, we create a slightly larger dataset and specify a data loader with a larger batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "q5JUCCCTDiL1"
      },
      "outputs": [],
      "source": [
        "train_dataset = XORDataset(size=2500, seed=42)\n",
        "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=numpy_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqDxIK7bDiL1"
      },
      "source": [
        "Now, we can write a small training function. In contrast to PyTorch, we do not need to explicitly push our model to GPU, since the parameters are already automatically created on GPU. Further, since the model itself is stateless, we do not have a `train()` or `eval()` function to switch between modes of e.g. dropout. When necessary, we can add an argument `train : bool` to the model forward pass. For this simple network here, however, this is not necessary.\n",
        "\n",
        "Following the PyTorch tutorial, let's write a function here that trains a model for several epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "kbIU6Y21DiL1"
      },
      "outputs": [],
      "source": [
        "def train_model(state, data_loader, num_epochs=100):\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for batch in data_loader:\n",
        "            state, loss, acc = train_step(state, batch)\n",
        "            # We could use the loss and accuracy for logging here, e.g. in TensorBoard\n",
        "            # For simplicity, we skip this part here\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c9ddb028438c41c48d19fb9f532175b0"
          ]
        },
        "id": "i1CXe0J4DiL1",
        "outputId": "332e004e-b190-4650-c331-7f4e0ac71328"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 199.66it/s]\n"
          ]
        }
      ],
      "source": [
        "trained_model_state = train_model(model_state, train_data_loader, num_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0oBcqLJDiL1"
      },
      "source": [
        "Training this model for 100 epochs does take barely a second... This shows the impressive speed JAX can reach, especially for small models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_du7yFhFDiL1"
      },
      "source": [
        "#### Saving a model\n",
        "\n",
        "After we finished training a model, we save the model to disk so that we can load the same weights at a later time. In JAX, this means we want to save the `state.params` dictionary. Luckily, the `flax.training` package again provides us with nice utilities for that, which uses TensorFlow as underlying framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "tP6dDQcCDiL1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Tensorflow library not found, tensorflow.io.gfile operations will use native shim calls. GCS paths (i.e. 'gs://...') cannot be accessed.\n"
          ]
        }
      ],
      "source": [
        "from flax.training import checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ5ZqJpjDiL1"
      },
      "source": [
        "To save the whole model state, we can write:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "QyWN9ADwDiL1",
        "outputId": "37738cd9-11b9-40da-ed93-e4db24817811"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Checkpoint path should be absolute. Got my_checkpoints\\my_model100.orbax-checkpoint-tmp-1704440518839098",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcheckpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmy_checkpoints/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Folder to save checkpoint in\u001b[39;49;00m\n\u001b[0;32m      2\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrained_model_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# What to save. To only save parameters, use model_state.params\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Training step or other metric to save best model on\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmy_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Checkpoint file name prefix\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Overwrite existing checkpoint files\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\jax\\lib\\site-packages\\flax\\training\\checkpoints.py:669\u001b[0m, in \u001b[0;36msave_checkpoint\u001b[1;34m(ckpt_dir, target, step, prefix, keep, overwrite, keep_every_n_steps, async_manager, orbax_checkpointer)\u001b[0m\n\u001b[0;32m    662\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    663\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrbax backend only accept pytree as save target. To save singular\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    664\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m objects like numbers or Numpy arrays, checkout\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    665\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m https://flax.readthedocs.io/en/latest/guides/use_checkpointing.html#if-you-don-t-save-pytrees\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    666\u001b[0m   )\n\u001b[0;32m    668\u001b[0m save_args \u001b[38;5;241m=\u001b[39m orbax_utils\u001b[38;5;241m.\u001b[39msave_args_from_target(target)\n\u001b[1;32m--> 669\u001b[0m \u001b[43morbax_checkpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;66;03m# Do a process check here in case people call this for multihost.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_index() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\jax\\lib\\site-packages\\orbax\\checkpoint\\checkpointer.py:150\u001b[0m, in \u001b[0;36mCheckpointer.save\u001b[1;34m(self, directory, force, *args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Ensure save operation atomicity and record time saved by checkpoint.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mprocess_index() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary_host:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m   utils\u001b[38;5;241m.\u001b[39mon_commit_callback(tmpdir, directory, checkpoint_start_time)\n\u001b[0;32m    152\u001b[0m utils\u001b[38;5;241m.\u001b[39msync_global_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheckpointer:save\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\jax\\lib\\site-packages\\orbax\\checkpoint\\pytree_checkpoint_handler.py:1411\u001b[0m, in \u001b[0;36mPyTreeCheckpointHandler.finalize\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_ocdbt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ocdbt_merge:\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m \u001b[43mtype_handlers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_ocdbt_per_process_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\jax\\lib\\site-packages\\orbax\\checkpoint\\type_handlers.py:714\u001b[0m, in \u001b[0;36mmerge_ocdbt_per_process_files\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m    710\u001b[0m ts_context \u001b[38;5;241m=\u001b[39m _DEFAULT_OCDBT_TS_CONTEXT\n\u001b[0;32m    712\u001b[0m open_ops \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 714\u001b[0m parent_tspec \u001b[38;5;241m=\u001b[39m \u001b[43mget_tensorstore_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ocdbt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m parent_tspec \u001b[38;5;241m=\u001b[39m parent_tspec[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkvstore\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    716\u001b[0m open_ops\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    717\u001b[0m     ts\u001b[38;5;241m.\u001b[39mKvStore\u001b[38;5;241m.\u001b[39mopen(\n\u001b[0;32m    718\u001b[0m         ts\u001b[38;5;241m.\u001b[39mKvStore\u001b[38;5;241m.\u001b[39mSpec(parent_tspec),\n\u001b[0;32m    719\u001b[0m         context\u001b[38;5;241m=\u001b[39mts_context,\n\u001b[0;32m    720\u001b[0m     )\n\u001b[0;32m    721\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\jax\\lib\\site-packages\\orbax\\checkpoint\\type_handlers.py:821\u001b[0m, in \u001b[0;36mget_tensorstore_spec\u001b[1;34m(directory, name, use_ocdbt, process_id, use_zarr3)\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ocdbt:\n\u001b[0;32m    820\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_gcs_path \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misabs(directory):\n\u001b[1;32m--> 821\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheckpoint path should be absolute. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    822\u001b[0m   base_path \u001b[38;5;241m=\u001b[39m directory \u001b[38;5;28;01mif\u001b[39;00m is_gcs_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefault_driver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    823\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m process_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mValueError\u001b[0m: Checkpoint path should be absolute. Got my_checkpoints\\my_model100.orbax-checkpoint-tmp-1704440518839098"
          ]
        }
      ],
      "source": [
        "checkpoints.save_checkpoint(ckpt_dir='my_checkpoints/',  # Folder to save checkpoint in\n",
        "                            target=trained_model_state,  # What to save. To only save parameters, use model_state.params\n",
        "                            step=100,  # Training step or other metric to save best model on\n",
        "                            prefix='my_model',  # Checkpoint file name prefix\n",
        "                            overwrite=True   # Overwrite existing checkpoint files\n",
        "                           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkBQB6oBDiL2"
      },
      "source": [
        "To load this state dict again, we can use `checkpoints.restore_checkpoint`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzfD5W46DiL2"
      },
      "outputs": [],
      "source": [
        "loaded_model_state = checkpoints.restore_checkpoint(\n",
        "                                             ckpt_dir='my_checkpoints/',   # Folder with the checkpoints\n",
        "                                             target=model_state,   # (optional) matching object to rebuild state in\n",
        "                                             prefix='my_model'  # Checkpoint file name prefix\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCqHfVZ9DiL2"
      },
      "source": [
        "The states `loaded_model_state` and `trained_model_state` have the identical parameter values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb3vDKa-DiL2"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Once we have trained a model, it is time to evaluate it on a held-out test set. As our dataset consist of randomly generated data points, we need to first create a test set with a corresponding data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "zXSIE5h9DiL2"
      },
      "outputs": [],
      "source": [
        "test_dataset = XORDataset(size=500, seed=123)\n",
        "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
        "test_data_loader = data.DataLoader(test_dataset,\n",
        "                                   batch_size=128,\n",
        "                                   shuffle=False,\n",
        "                                   drop_last=False,\n",
        "                                   collate_fn=numpy_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KguiwUIdDiL2"
      },
      "source": [
        "We can use our `eval_step` function to efficiently evaluate our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "_vInXctFDiL2"
      },
      "outputs": [],
      "source": [
        "def eval_model(state, data_loader):\n",
        "    all_accs, batch_sizes = [], []\n",
        "    for batch in data_loader:\n",
        "        batch_acc = eval_step(state, batch)\n",
        "        all_accs.append(batch_acc)\n",
        "        batch_sizes.append(batch[0].shape[0])\n",
        "    # Weighted average since some batches might be smaller\n",
        "    acc = sum([a*b for a,b in zip(all_accs, batch_sizes)]) / sum(batch_sizes)\n",
        "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "tzFlKvVTDiL2",
        "outputId": "6c82bf6f-c66f-47e6-c934-ae1d2ed534ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model: 100.00%\n"
          ]
        }
      ],
      "source": [
        "eval_model(trained_model_state, test_data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U2E9FS0DiL2"
      },
      "source": [
        "If we trained our model correctly, we should see a score close to 100% accuracy. However, this is only possible because of our simple task, and unfortunately, we usually don't get such high scores on test sets of more complex tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypzj5vgpDiL2"
      },
      "source": [
        "#### Binding model parameters\n",
        "\n",
        "Once we have trained the model, we might want to do multiple application of the same model and parameters. It can get a bit annoying to always write `model.apply(params, ...)` and keep track of the model and parameters separately. To prevent this, Flax's module can be bound to specific parameters to simplify our application. Specifically, we can bind the instance `model` of our `SimpleClassifier` class to our trained parameter as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Z_BDG-uXDiL2"
      },
      "outputs": [],
      "source": [
        "trained_model = model.bind(trained_model_state.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY5t1CASDiL2"
      },
      "source": [
        "With the model being binded to the parameters, we can use it as we would any PyTorch module. For instance, to apply it to an input array, we can simply run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "B27iY1DGDiL2",
        "outputId": "b144775b-5dd8-4bb1-aee6-b86cc9fdb60e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(128, 1)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_input, labels = next(iter(test_data_loader))\n",
        "out = trained_model(data_input)  # No explicit parameter passing necessary anymore\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkn0ySrYDiL2"
      },
      "source": [
        "This can simplify the analysis of models, and provide a more familiar interface to PyTorch users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbMluQQ2DiL2"
      },
      "source": [
        "#### Visualizing classification boundaries\n",
        "\n",
        "To visualize what our model has learned, we can perform a prediction for every data point in a range of $[-0.5, 1.5]$, and visualize the predicted class as in the sample figure at the beginning of this section. This shows where the model has created decision boundaries, and which points would be classified as $0$, and which as $1$. We therefore get a background image out of blue (class 0) and orange (class 1). The spots where the model is uncertain we will see a blurry overlap. The specific code is less relevant compared to the output figure which should hopefully show us a clear separation of classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "fUKHXkyaDiL2",
        "outputId": "def63caf-a702-47f1-c12d-f5bd59843fdf",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "application/pdf": "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",
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"296.111094pt\" height=\"285.283594pt\" viewBox=\"0 0 296.111094 285.283594\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
              " <metadata>\n",
              "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
              "   <cc:Work>\n",
              "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
              "    <dc:date>2024-01-05T17:25:16.745923</dc:date>\n",
              "    <dc:format>image/svg+xml</dc:format>\n",
              "    <dc:creator>\n",
              "     <cc:Agent>\n",
              "      <dc:title>Matplotlib v3.8.2, https://matplotlib.org/</dc:title>\n",
              "     </cc:Agent>\n",
              "    </dc:creator>\n",
              "   </cc:Work>\n",
              "  </rdf:RDF>\n",
              " </metadata>\n",
              " <defs>\n",
              "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
              " </defs>\n",
              " <g id=\"figure_1\">\n",
              "  <g id=\"patch_1\">\n",
              "   <path d=\"M 0 285.283594 \n",
              "L 296.111094 285.283594 \n",
              "L 296.111094 0 \n",
              "L 0 0 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "  </g>\n",
              "  <g id=\"axes_1\">\n",
              "   <g id=\"patch_2\">\n",
              "    <path d=\"M 59.506094 243.549375 \n",
              "L 281.266094 243.549375 \n",
              "L 281.266094 21.789375 \n",
              "L 59.506094 21.789375 \n",
              "z\n",
              "\" style=\"fill: #eaeaf2\"/>\n",
              "   </g>\n",
              "   <g clip-path=\"url(#p07331cbcdd)\">\n",
              "    <image xlink:href=\"data:image/png;base64,\n",
              "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\" id=\"image10926783c3\" transform=\"scale(1 -1) translate(0 -221.904)\" x=\"59.506094\" y=\"-21.645375\" width=\"221.904\" height=\"221.904\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_1\">\n",
              "    <g id=\"xtick_1\">\n",
              "     <g id=\"text_1\">\n",
              "      <!-- −0.5 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(48.64875 260.922969) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-2212\" d=\"M 3381 1997 \n",
              "L 356 1997 \n",
              "L 356 2522 \n",
              "L 3381 2522 \n",
              "L 3381 1997 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
              "Q 266 3072 433 3567 \n",
              "Q 600 4063 929 4331 \n",
              "Q 1259 4600 1759 4600 \n",
              "Q 2128 4600 2406 4451 \n",
              "Q 2684 4303 2865 4023 \n",
              "Q 3047 3744 3150 3342 \n",
              "Q 3253 2941 3253 2259 \n",
              "Q 3253 1453 3087 958 \n",
              "Q 2922 463 2592 192 \n",
              "Q 2263 -78 1759 -78 \n",
              "Q 1097 -78 719 397 \n",
              "Q 266 969 266 2259 \n",
              "z\n",
              "M 844 2259 \n",
              "Q 844 1131 1108 757 \n",
              "Q 1372 384 1759 384 \n",
              "Q 2147 384 2411 759 \n",
              "Q 2675 1134 2675 2259 \n",
              "Q 2675 3391 2411 3762 \n",
              "Q 2147 4134 1753 4134 \n",
              "Q 1366 4134 1134 3806 \n",
              "Q 844 3388 844 2259 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "        <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
              "L 581 641 \n",
              "L 1222 641 \n",
              "L 1222 0 \n",
              "L 581 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
              "L 856 1250 \n",
              "Q 922 819 1161 601 \n",
              "Q 1400 384 1738 384 \n",
              "Q 2144 384 2425 690 \n",
              "Q 2706 997 2706 1503 \n",
              "Q 2706 1984 2436 2262 \n",
              "Q 2166 2541 1728 2541 \n",
              "Q 1456 2541 1237 2417 \n",
              "Q 1019 2294 894 2097 \n",
              "L 366 2166 \n",
              "L 809 4519 \n",
              "L 3088 4519 \n",
              "L 3088 3981 \n",
              "L 1259 3981 \n",
              "L 1013 2750 \n",
              "Q 1425 3038 1878 3038 \n",
              "Q 2478 3038 2890 2622 \n",
              "Q 3303 2206 3303 1553 \n",
              "Q 3303 931 2941 478 \n",
              "Q 2500 -78 1738 -78 \n",
              "Q 1113 -78 717 272 \n",
              "Q 322 622 266 1200 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-2212\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"58.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"114.013672\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"141.796875\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_2\">\n",
              "     <g id=\"text_2\">\n",
              "      <!-- 0.0 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(107.301094 260.922969) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_3\">\n",
              "     <g id=\"text_3\">\n",
              "      <!-- 0.5 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(162.741094 260.922969) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_4\">\n",
              "     <g id=\"text_4\">\n",
              "      <!-- 1.0 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(218.181094 260.922969) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
              "L 1822 0 \n",
              "L 1822 3584 \n",
              "Q 1619 3391 1289 3197 \n",
              "Q 959 3003 697 2906 \n",
              "L 697 3450 \n",
              "Q 1169 3672 1522 3987 \n",
              "Q 1875 4303 2022 4600 \n",
              "L 2384 4600 \n",
              "L 2384 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_5\">\n",
              "     <g id=\"text_5\">\n",
              "      <!-- 1.5 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(273.621094 260.922969) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"83.398438\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_6\">\n",
              "     <!-- $x_1$ -->\n",
              "     <g style=\"fill: #262626\" transform=\"translate(163.966094 275.698594) scale(0.12 -0.12)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-Oblique-78\" d=\"M 3841 3500 \n",
              "L 2234 1784 \n",
              "L 3219 0 \n",
              "L 2559 0 \n",
              "L 1819 1388 \n",
              "L 531 0 \n",
              "L -166 0 \n",
              "L 1556 1844 \n",
              "L 641 3500 \n",
              "L 1300 3500 \n",
              "L 1972 2234 \n",
              "L 3144 3500 \n",
              "L 3841 3500 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
              "L 1825 531 \n",
              "L 1825 4091 \n",
              "L 703 3866 \n",
              "L 703 4441 \n",
              "L 1819 4666 \n",
              "L 2450 4666 \n",
              "L 2450 531 \n",
              "L 3481 531 \n",
              "L 3481 0 \n",
              "L 794 0 \n",
              "L 794 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(59.179688 -16.09375) scale(0.7)\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_2\">\n",
              "    <g id=\"ytick_1\">\n",
              "     <g id=\"text_7\">\n",
              "      <!-- −0.50 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(22.174375 247.486172) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-2212\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"58.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"114.013672\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"141.796875\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"197.412109\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_2\">\n",
              "     <g id=\"text_8\">\n",
              "      <!-- −0.25 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(22.174375 219.766172) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
              "L 3222 0 \n",
              "L 194 0 \n",
              "Q 188 203 259 391 \n",
              "Q 375 700 629 1000 \n",
              "Q 884 1300 1366 1694 \n",
              "Q 2113 2306 2375 2664 \n",
              "Q 2638 3022 2638 3341 \n",
              "Q 2638 3675 2398 3904 \n",
              "Q 2159 4134 1775 4134 \n",
              "Q 1369 4134 1125 3890 \n",
              "Q 881 3647 878 3216 \n",
              "L 300 3275 \n",
              "Q 359 3922 746 4261 \n",
              "Q 1134 4600 1788 4600 \n",
              "Q 2447 4600 2831 4234 \n",
              "Q 3216 3869 3216 3328 \n",
              "Q 3216 3053 3103 2787 \n",
              "Q 2991 2522 2730 2228 \n",
              "Q 2469 1934 1863 1422 \n",
              "Q 1356 997 1212 845 \n",
              "Q 1069 694 975 541 \n",
              "L 3222 541 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-2212\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"58.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"114.013672\"/>\n",
              "       <use xlink:href=\"#ArialMT-32\" x=\"141.796875\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"197.412109\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_3\">\n",
              "     <g id=\"text_9\">\n",
              "      <!-- 0.00 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 192.046172) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"139.013672\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_4\">\n",
              "     <g id=\"text_10\">\n",
              "      <!-- 0.25 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 164.326172) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"139.013672\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_5\">\n",
              "     <g id=\"text_11\">\n",
              "      <!-- 0.50 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 136.606172) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"83.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"139.013672\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_6\">\n",
              "     <g id=\"text_12\">\n",
              "      <!-- 0.75 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 108.886172) scale(0.11 -0.11)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-37\" d=\"M 303 3981 \n",
              "L 303 4522 \n",
              "L 3269 4522 \n",
              "L 3269 4084 \n",
              "Q 2831 3619 2401 2847 \n",
              "Q 1972 2075 1738 1259 \n",
              "Q 1569 684 1522 0 \n",
              "L 944 0 \n",
              "Q 953 541 1156 1306 \n",
              "Q 1359 2072 1739 2783 \n",
              "Q 2119 3494 2547 3981 \n",
              "L 303 3981 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-37\" x=\"83.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"139.013672\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_7\">\n",
              "     <g id=\"text_13\">\n",
              "      <!-- 1.00 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 81.166172) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"139.013672\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_8\">\n",
              "     <g id=\"text_14\">\n",
              "      <!-- 1.25 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 53.446172) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"139.013672\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_9\">\n",
              "     <g id=\"text_15\">\n",
              "      <!-- 1.50 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(28.599062 25.726172) scale(0.11 -0.11)\">\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"83.398438\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"139.013672\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_16\">\n",
              "     <!-- $x_2$ -->\n",
              "     <g style=\"fill: #262626\" transform=\"translate(15.789375 139.089375) rotate(-90) scale(0.12 -0.12)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
              "L 3431 531 \n",
              "L 3431 0 \n",
              "L 469 0 \n",
              "L 469 531 \n",
              "Q 828 903 1448 1529 \n",
              "Q 2069 2156 2228 2338 \n",
              "Q 2531 2678 2651 2914 \n",
              "Q 2772 3150 2772 3378 \n",
              "Q 2772 3750 2511 3984 \n",
              "Q 2250 4219 1831 4219 \n",
              "Q 1534 4219 1204 4116 \n",
              "Q 875 4013 500 3803 \n",
              "L 500 4441 \n",
              "Q 881 4594 1212 4672 \n",
              "Q 1544 4750 1819 4750 \n",
              "Q 2544 4750 2975 4387 \n",
              "Q 3406 4025 3406 3419 \n",
              "Q 3406 3131 3298 2873 \n",
              "Q 3191 2616 2906 2266 \n",
              "Q 2828 2175 2409 1742 \n",
              "Q 1991 1309 1228 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(59.179688 -16.09375) scale(0.7)\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"PathCollection_1\">\n",
              "    <defs>\n",
              "     <path id=\"m3928c5c81a\" d=\"M 0 3 \n",
              "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
              "C 2.683901 1.55874 3 0.795609 3 0 \n",
              "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
              "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
              "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
              "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
              "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
              "C -1.55874 2.683901 -0.795609 3 0 3 \n",
              "z\n",
              "\" style=\"stroke: #333333\"/>\n",
              "    </defs>\n",
              "    <g clip-path=\"url(#p07331cbcdd)\">\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"118.195681\" y=\"196.030103\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"101.73692\" y=\"180.829509\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"127.792602\" y=\"197.209101\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"125.628009\" y=\"183.53246\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"223.10523\" y=\"85.586799\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"228.89404\" y=\"68.057562\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"225.970262\" y=\"61.112586\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"222.891582\" y=\"47.068143\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"232.763496\" y=\"86.73354\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"103.072038\" y=\"182.759721\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"223.348341\" y=\"69.312538\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"109.995136\" y=\"178.613625\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"117.319965\" y=\"201.922127\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"227.746328\" y=\"72.956971\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"216.025881\" y=\"75.524871\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"229.793243\" y=\"71.011398\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"121.276128\" y=\"175.518223\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"125.524065\" y=\"180.886749\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"111.450389\" y=\"179.693925\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"251.491023\" y=\"97.93361\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"233.43535\" y=\"95.111167\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"217.894809\" y=\"69.693994\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"92.491312\" y=\"186.04197\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"217.038625\" y=\"78.501574\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"231.425392\" y=\"67.629883\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"212.517209\" y=\"80.938325\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"220.5599\" y=\"84.473492\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"245.401446\" y=\"72.738942\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"208.979318\" y=\"82.598563\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"239.873603\" y=\"85.076012\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"230.747167\" y=\"68.640234\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"223.025618\" y=\"91.064796\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"227.084771\" y=\"69.887676\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"138.597168\" y=\"209.754124\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"113.263101\" y=\"181.586114\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"118.061732\" y=\"195.013867\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"112.638434\" y=\"193.575769\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"229.784678\" y=\"84.912354\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"123.959109\" y=\"181.128051\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"123.232085\" y=\"181.34159\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"114.714337\" y=\"186.808449\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"124.09831\" y=\"179.08918\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"240.301243\" y=\"76.996488\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"238.66723\" y=\"68.451416\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"121.866334\" y=\"181.14228\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"114.810302\" y=\"198.058131\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"115.786615\" y=\"195.617744\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"105.792981\" y=\"191.672901\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"117.662283\" y=\"193.730361\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"109.723221\" y=\"185.536405\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"217.859987\" y=\"79.596078\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"118.393437\" y=\"171.750625\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"114.735242\" y=\"199.22542\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"229.404398\" y=\"86.40171\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"113.740161\" y=\"183.655195\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"122.59841\" y=\"192.558108\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"117.430831\" y=\"187.96975\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"131.036374\" y=\"177.47298\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"249.700576\" y=\"85.737728\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"235.49839\" y=\"75.196484\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"105.635258\" y=\"194.755441\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"202.276336\" y=\"83.05895\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"217.408833\" y=\"75.561815\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"229.615488\" y=\"56.426395\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"236.364389\" y=\"83.626085\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"113.676076\" y=\"174.384468\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"97.26708\" y=\"194.755245\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"103.108318\" y=\"189.688079\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"118.630791\" y=\"196.408594\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"238.902139\" y=\"76.480725\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"137.795666\" y=\"168.646156\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"223.065576\" y=\"66.456593\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"232.982028\" y=\"62.053993\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"222.838909\" y=\"69.273267\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"96.058989\" y=\"188.725288\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"92.022296\" y=\"189.097538\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"229.890936\" y=\"87.650765\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"104.016363\" y=\"182.520507\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"219.687233\" y=\"90.511448\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"247.610967\" y=\"76.838376\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"109.063897\" y=\"194.494048\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"244.065497\" y=\"79.990686\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"232.218957\" y=\"73.778227\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"149.084725\" y=\"175.695528\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"224.407744\" y=\"87.824408\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"97.133817\" y=\"185.85337\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"218.656896\" y=\"89.221576\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"133.65312\" y=\"178.333753\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"225.737692\" y=\"60.819756\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"103.445109\" y=\"190.21985\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"226.364103\" y=\"86.44295\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"117.944919\" y=\"188.666415\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"120.500263\" y=\"198.948507\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"226.927491\" y=\"68.897997\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"96.435728\" y=\"182.084597\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"218.478923\" y=\"70.902575\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"217.363079\" y=\"97.24191\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"225.093398\" y=\"90.657122\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"126.103868\" y=\"194.505952\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"124.212248\" y=\"200.635565\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"120.820563\" y=\"172.125263\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"198.420502\" y=\"86.065347\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#m3928c5c81a\" x=\"229.941363\" y=\"83.926363\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"PathCollection_2\">\n",
              "    <defs>\n",
              "     <path id=\"md18592ec31\" d=\"M 0 3 \n",
              "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
              "C 2.683901 1.55874 3 0.795609 3 0 \n",
              "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
              "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
              "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
              "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
              "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
              "C -1.55874 2.683901 -0.795609 3 0 3 \n",
              "z\n",
              "\" style=\"stroke: #333333\"/>\n",
              "    </defs>\n",
              "    <g clip-path=\"url(#p07331cbcdd)\">\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"107.40598\" y=\"74.65414\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"135.633802\" y=\"71.975514\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"104.138823\" y=\"68.502186\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"234.941096\" y=\"167.077735\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"215.963155\" y=\"197.155079\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"224.971191\" y=\"184.326682\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"231.073346\" y=\"188.916902\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"216.436846\" y=\"204.906002\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"226.471512\" y=\"200.78263\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"126.954966\" y=\"65.544821\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"99.670495\" y=\"87.627977\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"120.656805\" y=\"71.532515\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"231.536938\" y=\"145.390287\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"106.377008\" y=\"79.855222\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"220.444382\" y=\"187.201555\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"109.713313\" y=\"65.15509\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"115.658831\" y=\"89.179411\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"106.847789\" y=\"74.829277\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"115.451394\" y=\"84.45432\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"138.718145\" y=\"70.200478\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"218.488208\" y=\"178.657594\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"211.845414\" y=\"177.932121\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"138.476561\" y=\"65.781395\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"215.54829\" y=\"188.769392\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"189.886923\" y=\"199.467785\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"133.046271\" y=\"93.086782\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"110.066881\" y=\"75.779725\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"241.806936\" y=\"204.030215\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"238.723247\" y=\"187.995911\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"214.943128\" y=\"182.985572\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"117.153268\" y=\"83.884581\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"226.600056\" y=\"192.381732\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"243.411844\" y=\"201.834273\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"219.291217\" y=\"178.688987\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"235.800856\" y=\"184.702038\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"105.754197\" y=\"83.440663\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"129.112842\" y=\"83.788718\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"121.012309\" y=\"79.471287\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"112.532444\" y=\"65.046135\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"233.387593\" y=\"191.549613\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"229.420444\" y=\"189.552401\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"116.021585\" y=\"70.630273\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"216.75366\" y=\"164.908985\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"103.791373\" y=\"90.692295\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"236.638225\" y=\"189.739947\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"230.404678\" y=\"194.359953\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"105.829314\" y=\"74.527367\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"98.889734\" y=\"92.835331\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"124.455824\" y=\"79.002771\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"225.620819\" y=\"191.310022\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"231.584602\" y=\"171.114365\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"226.909131\" y=\"196.680508\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"226.097868\" y=\"182.58757\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"139.226629\" y=\"86.191783\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"104.984472\" y=\"71.774971\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"211.187346\" y=\"167.80216\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"238.903725\" y=\"193.311595\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"95.950858\" y=\"62.217644\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"225.884239\" y=\"187.588454\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"220.835765\" y=\"181.203215\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"116.279932\" y=\"71.525272\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"233.716482\" y=\"200.579407\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"97.935836\" y=\"63.062494\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"132.145267\" y=\"75.946774\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"104.247023\" y=\"69.622432\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"126.681904\" y=\"96.730277\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"101.826123\" y=\"99.840382\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"242.484223\" y=\"187.287812\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"243.884186\" y=\"203.41194\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"119.204611\" y=\"77.591896\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"100.482135\" y=\"69.804046\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"220.128335\" y=\"199.853934\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"114.251108\" y=\"66.638763\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"109.066597\" y=\"86.02075\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"224.639342\" y=\"199.588142\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"218.067535\" y=\"185.736766\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"224.580602\" y=\"190.559486\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"121.755974\" y=\"68.830123\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"111.89632\" y=\"102.753078\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"209.025654\" y=\"172.953473\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"217.439677\" y=\"203.879324\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"115.803954\" y=\"86.779294\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"131.834494\" y=\"71.253934\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"105.237239\" y=\"92.561859\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"236.09555\" y=\"166.937764\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"210.318777\" y=\"181.867172\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"107.731769\" y=\"82.630623\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"219.25763\" y=\"197.689305\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"223.17664\" y=\"198.172441\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"108.550853\" y=\"68.853598\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"96.899904\" y=\"76.696204\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"228.705897\" y=\"198.136438\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"232.906805\" y=\"206.532309\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"218.598532\" y=\"187.583819\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"105.40583\" y=\"81.493326\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"121.34467\" y=\"79.480745\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     <use xlink:href=\"#md18592ec31\" x=\"226.786204\" y=\"189.835524\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"patch_3\">\n",
              "    <path d=\"M 59.506094 243.549375 \n",
              "L 59.506094 21.789375 \n",
              "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_4\">\n",
              "    <path d=\"M 281.266094 243.549375 \n",
              "L 281.266094 21.789375 \n",
              "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_5\">\n",
              "    <path d=\"M 59.506094 243.549375 \n",
              "L 281.266094 243.549375 \n",
              "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_6\">\n",
              "    <path d=\"M 59.506094 21.789375 \n",
              "L 281.266094 21.789375 \n",
              "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"text_17\">\n",
              "    <!-- Dataset samples -->\n",
              "    <g style=\"fill: #262626\" transform=\"translate(125.702031 15.789375) scale(0.12 -0.12)\">\n",
              "     <defs>\n",
              "      <path id=\"ArialMT-44\" d=\"M 494 0 \n",
              "L 494 4581 \n",
              "L 2072 4581 \n",
              "Q 2606 4581 2888 4516 \n",
              "Q 3281 4425 3559 4188 \n",
              "Q 3922 3881 4101 3404 \n",
              "Q 4281 2928 4281 2316 \n",
              "Q 4281 1794 4159 1391 \n",
              "Q 4038 988 3847 723 \n",
              "Q 3656 459 3429 307 \n",
              "Q 3203 156 2883 78 \n",
              "Q 2563 0 2147 0 \n",
              "L 494 0 \n",
              "z\n",
              "M 1100 541 \n",
              "L 2078 541 \n",
              "Q 2531 541 2789 625 \n",
              "Q 3047 709 3200 863 \n",
              "Q 3416 1078 3536 1442 \n",
              "Q 3656 1806 3656 2325 \n",
              "Q 3656 3044 3420 3430 \n",
              "Q 3184 3816 2847 3947 \n",
              "Q 2603 4041 2063 4041 \n",
              "L 1100 4041 \n",
              "L 1100 541 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
              "Q 2275 144 1986 34 \n",
              "Q 1697 -75 1366 -75 \n",
              "Q 819 -75 525 192 \n",
              "Q 231 459 231 875 \n",
              "Q 231 1119 342 1320 \n",
              "Q 453 1522 633 1644 \n",
              "Q 813 1766 1038 1828 \n",
              "Q 1203 1872 1538 1913 \n",
              "Q 2219 1994 2541 2106 \n",
              "Q 2544 2222 2544 2253 \n",
              "Q 2544 2597 2384 2738 \n",
              "Q 2169 2928 1744 2928 \n",
              "Q 1347 2928 1158 2789 \n",
              "Q 969 2650 878 2297 \n",
              "L 328 2372 \n",
              "Q 403 2725 575 2942 \n",
              "Q 747 3159 1072 3276 \n",
              "Q 1397 3394 1825 3394 \n",
              "Q 2250 3394 2515 3294 \n",
              "Q 2781 3194 2906 3042 \n",
              "Q 3031 2891 3081 2659 \n",
              "Q 3109 2516 3109 2141 \n",
              "L 3109 1391 \n",
              "Q 3109 606 3145 398 \n",
              "Q 3181 191 3288 0 \n",
              "L 2700 0 \n",
              "Q 2613 175 2588 409 \n",
              "z\n",
              "M 2541 1666 \n",
              "Q 2234 1541 1622 1453 \n",
              "Q 1275 1403 1131 1340 \n",
              "Q 988 1278 909 1158 \n",
              "Q 831 1038 831 891 \n",
              "Q 831 666 1001 516 \n",
              "Q 1172 366 1500 366 \n",
              "Q 1825 366 2078 508 \n",
              "Q 2331 650 2450 897 \n",
              "Q 2541 1088 2541 1459 \n",
              "L 2541 1666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
              "L 1731 6 \n",
              "Q 1494 -44 1306 -44 \n",
              "Q 1000 -44 831 53 \n",
              "Q 663 150 594 308 \n",
              "Q 525 466 525 972 \n",
              "L 525 2881 \n",
              "L 113 2881 \n",
              "L 113 3319 \n",
              "L 525 3319 \n",
              "L 525 4141 \n",
              "L 1084 4478 \n",
              "L 1084 3319 \n",
              "L 1650 3319 \n",
              "L 1650 2881 \n",
              "L 1084 2881 \n",
              "L 1084 941 \n",
              "Q 1084 700 1114 631 \n",
              "Q 1144 563 1211 522 \n",
              "Q 1278 481 1403 481 \n",
              "Q 1497 481 1650 503 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-73\" d=\"M 197 991 \n",
              "L 753 1078 \n",
              "Q 800 744 1014 566 \n",
              "Q 1228 388 1613 388 \n",
              "Q 2000 388 2187 545 \n",
              "Q 2375 703 2375 916 \n",
              "Q 2375 1106 2209 1216 \n",
              "Q 2094 1291 1634 1406 \n",
              "Q 1016 1563 777 1677 \n",
              "Q 538 1791 414 1992 \n",
              "Q 291 2194 291 2438 \n",
              "Q 291 2659 392 2848 \n",
              "Q 494 3038 669 3163 \n",
              "Q 800 3259 1026 3326 \n",
              "Q 1253 3394 1513 3394 \n",
              "Q 1903 3394 2198 3281 \n",
              "Q 2494 3169 2634 2976 \n",
              "Q 2775 2784 2828 2463 \n",
              "L 2278 2388 \n",
              "Q 2241 2644 2061 2787 \n",
              "Q 1881 2931 1553 2931 \n",
              "Q 1166 2931 1000 2803 \n",
              "Q 834 2675 834 2503 \n",
              "Q 834 2394 903 2306 \n",
              "Q 972 2216 1119 2156 \n",
              "Q 1203 2125 1616 2013 \n",
              "Q 2213 1853 2448 1751 \n",
              "Q 2684 1650 2818 1456 \n",
              "Q 2953 1263 2953 975 \n",
              "Q 2953 694 2789 445 \n",
              "Q 2625 197 2315 61 \n",
              "Q 2006 -75 1616 -75 \n",
              "Q 969 -75 630 194 \n",
              "Q 291 463 197 991 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
              "L 3275 997 \n",
              "Q 3138 488 2766 206 \n",
              "Q 2394 -75 1816 -75 \n",
              "Q 1088 -75 661 373 \n",
              "Q 234 822 234 1631 \n",
              "Q 234 2469 665 2931 \n",
              "Q 1097 3394 1784 3394 \n",
              "Q 2450 3394 2872 2941 \n",
              "Q 3294 2488 3294 1666 \n",
              "Q 3294 1616 3291 1516 \n",
              "L 816 1516 \n",
              "Q 847 969 1125 678 \n",
              "Q 1403 388 1819 388 \n",
              "Q 2128 388 2347 550 \n",
              "Q 2566 713 2694 1069 \n",
              "z\n",
              "M 847 1978 \n",
              "L 2700 1978 \n",
              "Q 2663 2397 2488 2606 \n",
              "Q 2219 2931 1791 2931 \n",
              "Q 1403 2931 1139 2672 \n",
              "Q 875 2413 847 1978 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
              "L 422 3319 \n",
              "L 925 3319 \n",
              "L 925 2853 \n",
              "Q 1081 3097 1340 3245 \n",
              "Q 1600 3394 1931 3394 \n",
              "Q 2300 3394 2536 3241 \n",
              "Q 2772 3088 2869 2813 \n",
              "Q 3263 3394 3894 3394 \n",
              "Q 4388 3394 4653 3120 \n",
              "Q 4919 2847 4919 2278 \n",
              "L 4919 0 \n",
              "L 4359 0 \n",
              "L 4359 2091 \n",
              "Q 4359 2428 4304 2576 \n",
              "Q 4250 2725 4106 2815 \n",
              "Q 3963 2906 3769 2906 \n",
              "Q 3419 2906 3187 2673 \n",
              "Q 2956 2441 2956 1928 \n",
              "L 2956 0 \n",
              "L 2394 0 \n",
              "L 2394 2156 \n",
              "Q 2394 2531 2256 2718 \n",
              "Q 2119 2906 1806 2906 \n",
              "Q 1569 2906 1367 2781 \n",
              "Q 1166 2656 1075 2415 \n",
              "Q 984 2175 984 1722 \n",
              "L 984 0 \n",
              "L 422 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
              "L 422 3319 \n",
              "L 934 3319 \n",
              "L 934 2888 \n",
              "Q 1116 3141 1344 3267 \n",
              "Q 1572 3394 1897 3394 \n",
              "Q 2322 3394 2647 3175 \n",
              "Q 2972 2956 3137 2557 \n",
              "Q 3303 2159 3303 1684 \n",
              "Q 3303 1175 3120 767 \n",
              "Q 2938 359 2589 142 \n",
              "Q 2241 -75 1856 -75 \n",
              "Q 1575 -75 1351 44 \n",
              "Q 1128 163 984 344 \n",
              "L 984 -1272 \n",
              "L 422 -1272 \n",
              "z\n",
              "M 931 1641 \n",
              "Q 931 1000 1190 694 \n",
              "Q 1450 388 1819 388 \n",
              "Q 2194 388 2461 705 \n",
              "Q 2728 1022 2728 1688 \n",
              "Q 2728 2322 2467 2637 \n",
              "Q 2206 2953 1844 2953 \n",
              "Q 1484 2953 1207 2617 \n",
              "Q 931 2281 931 1641 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
              "L 409 4581 \n",
              "L 972 4581 \n",
              "L 972 0 \n",
              "L 409 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "     </defs>\n",
              "     <use xlink:href=\"#ArialMT-44\"/>\n",
              "     <use xlink:href=\"#ArialMT-61\" x=\"72.216797\"/>\n",
              "     <use xlink:href=\"#ArialMT-74\" x=\"127.832031\"/>\n",
              "     <use xlink:href=\"#ArialMT-61\" x=\"155.615234\"/>\n",
              "     <use xlink:href=\"#ArialMT-73\" x=\"211.230469\"/>\n",
              "     <use xlink:href=\"#ArialMT-65\" x=\"261.230469\"/>\n",
              "     <use xlink:href=\"#ArialMT-74\" x=\"316.845703\"/>\n",
              "     <use xlink:href=\"#ArialMT-20\" x=\"344.628906\"/>\n",
              "     <use xlink:href=\"#ArialMT-73\" x=\"372.412109\"/>\n",
              "     <use xlink:href=\"#ArialMT-61\" x=\"422.412109\"/>\n",
              "     <use xlink:href=\"#ArialMT-6d\" x=\"478.027344\"/>\n",
              "     <use xlink:href=\"#ArialMT-70\" x=\"561.328125\"/>\n",
              "     <use xlink:href=\"#ArialMT-6c\" x=\"616.943359\"/>\n",
              "     <use xlink:href=\"#ArialMT-65\" x=\"639.160156\"/>\n",
              "     <use xlink:href=\"#ArialMT-73\" x=\"694.775391\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"legend_1\">\n",
              "    <g id=\"patch_7\">\n",
              "     <path d=\"M 67.206094 61.709063 \n",
              "L 139.084219 61.709063 \n",
              "Q 141.284219 61.709063 141.284219 59.509063 \n",
              "L 141.284219 29.489375 \n",
              "Q 141.284219 27.289375 139.084219 27.289375 \n",
              "L 67.206094 27.289375 \n",
              "Q 65.006094 27.289375 65.006094 29.489375 \n",
              "L 65.006094 59.509063 \n",
              "Q 65.006094 61.709063 67.206094 61.709063 \n",
              "z\n",
              "\" style=\"fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"PathCollection_3\">\n",
              "     <g>\n",
              "      <use xlink:href=\"#m3928c5c81a\" x=\"80.406094\" y=\"36.675469\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_18\">\n",
              "     <!-- Class 0 -->\n",
              "     <g style=\"fill: #262626\" transform=\"translate(100.206094 39.562969) scale(0.11 -0.11)\">\n",
              "      <defs>\n",
              "       <path id=\"ArialMT-43\" d=\"M 3763 1606 \n",
              "L 4369 1453 \n",
              "Q 4178 706 3683 314 \n",
              "Q 3188 -78 2472 -78 \n",
              "Q 1731 -78 1267 223 \n",
              "Q 803 525 561 1097 \n",
              "Q 319 1669 319 2325 \n",
              "Q 319 3041 592 3573 \n",
              "Q 866 4106 1370 4382 \n",
              "Q 1875 4659 2481 4659 \n",
              "Q 3169 4659 3637 4309 \n",
              "Q 4106 3959 4291 3325 \n",
              "L 3694 3184 \n",
              "Q 3534 3684 3231 3912 \n",
              "Q 2928 4141 2469 4141 \n",
              "Q 1941 4141 1586 3887 \n",
              "Q 1231 3634 1087 3207 \n",
              "Q 944 2781 944 2328 \n",
              "Q 944 1744 1114 1308 \n",
              "Q 1284 872 1643 656 \n",
              "Q 2003 441 2422 441 \n",
              "Q 2931 441 3284 734 \n",
              "Q 3638 1028 3763 1606 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#ArialMT-43\"/>\n",
              "      <use xlink:href=\"#ArialMT-6c\" x=\"72.216797\"/>\n",
              "      <use xlink:href=\"#ArialMT-61\" x=\"94.433594\"/>\n",
              "      <use xlink:href=\"#ArialMT-73\" x=\"150.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-73\" x=\"200.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-20\" x=\"250.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-30\" x=\"277.832031\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"PathCollection_4\">\n",
              "     <g>\n",
              "      <use xlink:href=\"#md18592ec31\" x=\"80.406094\" y=\"52.235313\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_19\">\n",
              "     <!-- Class 1 -->\n",
              "     <g style=\"fill: #262626\" transform=\"translate(100.206094 55.122813) scale(0.11 -0.11)\">\n",
              "      <use xlink:href=\"#ArialMT-43\"/>\n",
              "      <use xlink:href=\"#ArialMT-6c\" x=\"72.216797\"/>\n",
              "      <use xlink:href=\"#ArialMT-61\" x=\"94.433594\"/>\n",
              "      <use xlink:href=\"#ArialMT-73\" x=\"150.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-73\" x=\"200.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-20\" x=\"250.048828\"/>\n",
              "      <use xlink:href=\"#ArialMT-31\" x=\"277.832031\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              " </g>\n",
              " <defs>\n",
              "  <clipPath id=\"p07331cbcdd\">\n",
              "   <rect x=\"59.506094\" y=\"21.789375\" width=\"221.76\" height=\"221.76\"/>\n",
              "  </clipPath>\n",
              " </defs>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<Figure size 2000x2000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def visualize_classification(model, data, label):\n",
        "    data_0 = data[label == 0]\n",
        "    data_1 = data[label == 1]\n",
        "\n",
        "    fig = plt.figure(figsize=(4,4), dpi=500)\n",
        "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "    plt.title(\"Dataset samples\")\n",
        "    plt.ylabel(r\"$x_2$\")\n",
        "    plt.xlabel(r\"$x_1$\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Let's make use of a lot of operations we have learned above\n",
        "    c0 = np.array(to_rgba(\"C0\"))\n",
        "    c1 = np.array(to_rgba(\"C1\"))\n",
        "    x1 = jnp.arange(-0.5, 1.5, step=0.01)\n",
        "    x2 = jnp.arange(-0.5, 1.5, step=0.01)\n",
        "    xx1, xx2 = jnp.meshgrid(x1, x2, indexing='ij')  # Meshgrid function as in numpy\n",
        "    model_inputs = np.stack([xx1, xx2], axis=-1)\n",
        "    logits = model(model_inputs)\n",
        "    preds = nn.sigmoid(logits)\n",
        "    output_image = (1 - preds) * c0[None,None] + preds * c1[None,None]  # Specifying \"None\" in a dimension creates a new one\n",
        "    output_image = jax.device_get(output_image)  # Convert to numpy array. This only works for tensors on CPU, hence first push to CPU\n",
        "    plt.imshow(output_image, origin='lower', extent=(-0.5, 1.5, -0.5, 1.5))\n",
        "    plt.grid(False)\n",
        "    return fig\n",
        "\n",
        "_ = visualize_classification(trained_model, dataset.data, dataset.label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJd9VwcqDiL2"
      },
      "source": [
        "The decision boundaries might not look exactly as in the figure in the preamble of this section, since this has been created with the PyTorch version of the tutorial. Nevertheless, the result on the accuracy metric should be the approximately the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8d77Xh8DiL2"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "This concludes our tutorial on training a neural network with JAX. While the functional programming perspective of JAX may seem very different to PyTorch at first, it enables a considerable speedup in training, not only for tiny models like here. If you are interested in seeing more practical use cases of JAX, we recommend checking out our other JAX Tutorials, such as:\n",
        "\n",
        "* [Tutorial 5 (JAX): Inception, ResNet and DenseNet](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial5/Inception_ResNet_DenseNet.html) gives an intro to training convolutional classifiers on CIFAR10;\n",
        "* [Tutorial 6 (JAX): Transformers and Multi-Head Attention](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial6/Transformers_and_MHAttention.html) builds a Transformer from scratch with Flax;\n",
        "* [Tutorial 7 (JAX): Graph Neural Networks](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial7/GNN_overview.html) implements basic Graph Neural Network layers;\n",
        "* [Tutorial 9 (JAX): Deep Autoencoders](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial9/AE_CIFAR10.html) shows how to train autoencoders on CIFAR10;\n",
        "* [Tutorial 11 (JAX): Normalizing Flows for image modeling](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial11/NF_image_modeling.html) discusses Normalizing Flows as generative model on images;\n",
        "* [Tutorial 15 (JAX): Vision Transformers](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial15/Vision_Transformer.html) trains a Transformer on image classification for CIFAR10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A097Qx_CDiL2"
      },
      "source": [
        "## ✨ The Fancy Bits ✨\n",
        "\n",
        "After reading this tutorial, you might wonder why we left out some key advertisement points of JAX: automatic vectorization, easy parallelization on multiple accelerators, etc. The reason why we did not include them in our previous discuss is that for building simple networks, and actual most models in our tutorials, you do not really need these methods. However, since they can be handy at some times, for instance, if you have access to a large cluster or are faced with functions that are annoying to vectorize, we review them here in a separate section: the Fancy Bits of JAX (the title is inspired by JAX's tutorial [🔪 JAX - The Sharp Bits 🔪](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHmRXVciDiL2"
      },
      "source": [
        "### Automatic Vectorization with vmap\n",
        "\n",
        "In machine learning, we often vectorize methods to efficiently process multiple inputs or batch elements at the same time. Usually, we have to write the code ourselves to support additional dimensions to vectorize over. However, since JAX can already transform functions to run efficiently on accelerators or calculate gradients, it can also automatically vectorize a function. For instance, let's consider a simple linear layer where we write a function for a single input `x` of shape `[c_in]`, a weight matrix `[c_in, c_out]`, and a bias vector `[c_out]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "2BoxxBceDiL2"
      },
      "outputs": [],
      "source": [
        "def simple_linear(x, w, b):\n",
        "    # We could already vectorize this function with matmul, but as an example,\n",
        "    # let us use a non-vectorized function with same output\n",
        "    return (x[:,None] * w).sum(axis=0) + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Qag0cieNDiL3",
        "outputId": "af5f7168-53f7-41f5-9153-1c3e52269008"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([2.9875855, 4.6601286, 2.199494 ], dtype=float32)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example inputs\n",
        "rng, x_rng, w_rng, b_rng = jax.random.split(rng, 4)\n",
        "x_in = jax.random.normal(x_rng, (4,))\n",
        "w_in = jax.random.normal(w_rng, (4, 3))\n",
        "b_in = jax.random.normal(b_rng, (3,))\n",
        "\n",
        "simple_linear(x_in, w_in, b_in)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE-aitNiDiL3"
      },
      "source": [
        "Now, we would like the function to support a batch dimension on `x`, i.e. `[batch, c_in]`. Our naive implementation above does not support this, since we specialized the axis we sum over. So, let's make JAX do the work for us and vectorize the function by using `jax.vmap`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "CfXj6N7pDiL3"
      },
      "outputs": [],
      "source": [
        "vectorized_linear = jax.vmap(simple_linear,\n",
        "                             in_axes=(0, None, None),  # Which axes to vectorize for each input\n",
        "                             out_axes=0  # Which axes to map to in the output\n",
        "                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LEtCeUVDiL3"
      },
      "source": [
        "Specifying `None` for the in-axes of the input arguments `w` and `b` means that we do not want to vectorize any of their input dimensions. With this vmap specification, the function `vectorized_linear` now supports an extra batch dimension in `x`! Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "BeYfpvg_DiL3",
        "outputId": "feedf5c2-f186-400b-a3c4-2e297c5ecdf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[2.9875855, 4.6601286, 2.199494 ],\n",
              "       [2.9875855, 4.6601286, 2.199494 ],\n",
              "       [2.9875855, 4.6601286, 2.199494 ],\n",
              "       [2.9875855, 4.6601286, 2.199494 ],\n",
              "       [2.9875855, 4.6601286, 2.199494 ]], dtype=float32)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_vec_in = jnp.stack([x_in]*5, axis=0)\n",
        "\n",
        "vectorized_linear(x_vec_in, w_in, b_in)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D10eDqnxDiL3"
      },
      "source": [
        "The new function indeed vectorized our code, calculating $N$ applications of the weights and bias to the input. We can also vectorize the code to run multiple inputs `x` on multiple weights `w` and biases `b` by changing the input argument `in_axes` to `(0, 0, 0)`, or simply `0`. Morever, we can again stack multiple function transformations, such as jitting a vectorized function. Further details on `jax.vmap` can be found in this [tutorial](\n",
        "https://jax.readthedocs.io/en/latest/jax-101/03-vectorization.html\n",
        ") and its [documentation](https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html?highlight=vmap)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6-g79omDiL3"
      },
      "source": [
        "### Parallel evaluation with pmap\n",
        "\n",
        "`jax.vmap` vectorizes a function on a single accelerator. But what if we have multiple GPUs or TPUs available? In PyTorch, we can parallelize a model over multiple GPUs using `nn.DistributedDataParallel`. In JAX, this is yet another function transformation: `jax.pmap`. Similar to `jax.vmap`, we can specify over which axes each input should be parallelized. In a network training, we usually want to parallelize over an extra batch dimension in the data, while the parameters are identical for all devices. For more details on `jax.pmap`, see [Parallel Evaluation in JAX](https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6gYqBpRDiL3"
      },
      "source": [
        "### Working with PyTrees\n",
        "\n",
        "Network parameters in Flax are stored in a PyTree. We have visited them before, but what we haven't discuss yet is JAX's utilities to operate on pytrees! One common application is to obtain a list of all parameters in the network. This corresponds to extracting all leafs from a PyTree, for which JAX provides the function `jax.tree_leaves`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "FM6QGLy5DiL3",
        "outputId": "32783dbd-66f7-4fa3-8339-76533ff08b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have parameters with the following shapes: (8,), (2, 8), (1,), (8, 1)\n",
            "Overall parameter count: 33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\197796\\AppData\\Local\\Temp\\ipykernel_13448\\1496422120.py:1: DeprecationWarning: jax.tree_leaves is deprecated: use jax.tree_util.tree_leaves.\n",
            "  parameters = jax.tree_leaves(model_state.params)\n"
          ]
        }
      ],
      "source": [
        "parameters = jax.tree_leaves(model_state.params)\n",
        "print('We have parameters with the following shapes:', ', '.join([str(p.shape) for p in parameters]))\n",
        "print('Overall parameter count:', sum([np.prod(p.shape) for p in parameters]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ly6zt_cDiL3"
      },
      "source": [
        "We can also create new PyTrees that are the result of applying a function on all elements in the tree using `jax.tree_map`. For instance, let's obtain a PyTree with all parameter shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "0Oq6XvwWDiL3",
        "outputId": "a44b6d72-0182-4348-d88b-7ee48f6106fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'params': {'linear1': {'bias': (8,), 'kernel': (2, 8)},\n",
              "  'linear2': {'bias': (1,), 'kernel': (8, 1)}}}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.tree_map(lambda p: p.shape, model_state.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHmn13nIDiL3"
      },
      "source": [
        "The nodes of PyTrees do not necessarily need to be NumPy or JAX arrays, but can be arbitrary objects. Overall, PyTrees provide a simple, structured representation of data useful in many applications. More details can be found in JAX's Tutorial [Working with PyTrees](https://jax.readthedocs.io/en/latest/jax-101/05.1-pytrees.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Fv926ODiL3"
      },
      "source": [
        "## 🔪 The Sharp Bits 🔪\n",
        "\n",
        "Since JAX functions need to be written with certain constraints, there are situations where this can get annoying or difficult. A great overview of those, why they are needed, and most importantly, what to do about them, can be found in the original JAX tutorial [🔪 JAX - The Sharp Bits 🔪](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html). In this final section of the tutorial, we want to visit a few of those points we have not explicitly discussed yet. Furthermore, we also focus on the combination with Flax, and what can be annoying when training models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cFWNF5VDiL3"
      },
      "source": [
        "### Dynamic shapes\n",
        "\n",
        "JAX has the great advantage of providing just-in-time compilation of functions to speed up the computation. For this, it uses its intermediate representation jaxpr, which is specialized to the shapes of the input arguments. However, this also means that a jitted function is specialized to a certain shape, and running the jitted function with a different input shape requires recompiling the function. For instance, consider the following simple function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Gtgp93kUDiL3"
      },
      "outputs": [],
      "source": [
        "def my_function(x):\n",
        "    print('Running the function with shape', x.shape)\n",
        "    return x.mean()\n",
        "\n",
        "jitted_function = jax.jit(my_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibZThS2sDiL3"
      },
      "source": [
        "The print statement is only executed once when the function is compiled, and for all consecutive function calls, this print statement will be ignored since it is not part of the jaxpr representation. Let's run the function now with multiple different input shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "-ODtavEPDiL3",
        "outputId": "8028fda5-486d-4ccc-fbff-5bad4f0d0146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running the function with shape (1,)\n",
            "Running the function with shape (2,)\n",
            "Running the function with shape (3,)\n",
            "Running the function with shape (4,)\n",
            "Running the function with shape (5,)\n",
            "Running the function with shape (6,)\n",
            "Running the function with shape (7,)\n",
            "Running the function with shape (8,)\n",
            "Running the function with shape (9,)\n",
            "Running the function with shape (10,)\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    jitted_function(jnp.zeros(i+1,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqKF_E9aDiL3"
      },
      "source": [
        "As we can see, the function is compiled for every different input we give it. This can become inefficient if we actually work with many different shapes. However, running the function again with one of the previous input shapes will not require another compilation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "nxwM_R6aDiL3"
      },
      "outputs": [],
      "source": [
        "# Running the functions a second time will not print out anything since\n",
        "# the functions are already jitted for the respective input shapes.\n",
        "for i in range(10):\n",
        "    jitted_function(jnp.zeros(i+1,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aqB5c7IDiL3"
      },
      "source": [
        "If we have a very limited set of different shapes, we do not see a big performance difference. For instance, in our evaluation, the last batch size is smaller than the previous since we have a limited size of the evaluation dataset. However, for other applications, we might encounter this problem much more often: NLP and time series, and graphs. In these cases, it is recommend to pad the batches to prevent many re-compilations (see Flax's [padding guide](https://flax.readthedocs.io/en/latest/howtos/full_eval.html) for details). We briefly review the two scenarios below.\n",
        "\n",
        "#### NLP and time series\n",
        "\n",
        "In Natural Language Processing, our data consist of sentences which greatly vary in size. Already for batching the elements, we need to apply padding, such that the shape of the batch is determined by the largest sentence in the batch. However, this largest length can vary between batches, especially when we shuffle the dataset before each epoch. In PyTorch, this is not a problem, since the dynamic computation graph allows us to stop the computation whenever we need to. In contrast, JAX would need to recompile the forward pass for every single largest sentence length, which can quickly become very expensive. Padding is needed to reduce the number of compilations, but at the same time introduces unnecessary computation. Hence, we have a tradeoff between number of compilations and extra compute per batch. In the extreme case, PyTorch may even become faster than JAX here.\n",
        "\n",
        "#### Graphs\n",
        "\n",
        "Similar to NLP, graphs can vary in their size. Often, graphs differ in their number of nodes, but especially in the number of edges. Furthermore, when we start batching the graphs, the variation of node sizes and edge count considerably increases. Again, padding is needed to reduce the number of compilations, and we will revisit this topic in Tutorial 7 (TBD)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_EeKYujDiL3"
      },
      "source": [
        "### Debugging in jitted functions\n",
        "\n",
        "During coding, we likely want to debug our model and sometimes print out intermediate values. In JAX, when jitting functions, this is not as straightforward. As we could see from the previous cells, a print statement is only executed once during compilation, and afterwards removed since it is not part of the jaxpr representation. Furthermore, there can be issues when tracking NaNs in your code (see the [sharp bits tutorial](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#debugging-nans)), and errors like out-of-bounds indexing are silently handled on accelerators by returning -1 instead of an error (see the corresponding section in the [sharp bits tutorial](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#out-of-bounds-indexing)). However, if necessary, one can either run the unjitted version of the forward pass first, and even introduce print statements to the jitted version where needed (see [here](https://github.com/google/jax/issues/196) for a great explanation). Still, it is not as straight-forward as in PyTorch, for example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0XN7kVoDiL3"
      },
      "source": [
        "### Modules with different train and evaluation functions\n",
        "\n",
        "Certain deep learning layers have different behaviors under evaluation than during training. For instance, dropout randomly masks out a number of neurons during training, but leaves the graph untouched during evaluation. In PyTorch, we can easily switch between the two states via `model.train()` and `model.eval()` without having to manually specify it in the dropout module instance. However, in JAX, we do not have global states in the model, and thus need to pass this information to every module in the forward pass that may need it. In our example above, this was not needed, since the forward pass of the simple classifier is identical during training and evaluation. Alternatively, since the parameters are not bound to a specific model during training, one can also create two models: one training model, and one evaluation model. Nonetheless, one still needs to add the information to every module with changing behaviors, which adds a certain overhead compared to PyTorch. We will discuss two common modules with such behaviors below: dropout and BatchNorm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgKKIXPfDiL3"
      },
      "source": [
        "#### Dropout\n",
        "\n",
        "In Flax, [Dropout](https://flax.readthedocs.io/en/latest/_autosummary/flax.linen.Dropout.html) has an argument `deterministic` which turns off dropout when True, and otherwise applies the random masking as intended during training. This deterministic switch can either be defined in the constructor, or in every forward call. Furthermore, dropout has the special case that it is a random operation during training, meaning that it also needs a PRNG state. Fortunately, we do not have to pass this state in every PRNG state, but instead, can simply pass `rngs={'dropout': dropout_rng}` with `dropout_rng` being the PRNG state. For an example, see our [Tutorial 6](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial6/Transformers_and_MHAttention.html) on Transformers in which we use dropout in several occasions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFYVXB4WDiL4"
      },
      "source": [
        "#### BatchNorm\n",
        "\n",
        "Batch Normalization transforms the input in two different ways. During training, we determine the mean and standard deviation of the input, and normalize the data with it to a zero mean and standard deviation of one. During evaluation, on the other hand, we take a running statistic over the previous several batches, and use those to estimate the mean and standard deviation. This is necessary to keep the evaluation stable and invariant to the specific batches we choose. Still, in the Flax module ([documentation](https://flax.readthedocs.io/en/latest/_autosummary/flax.linen.BatchNorm.html)), we need to give the argument `use_running_average` (bool) to either the constructor or each forward pass. Furthermore, BatchNorm has a specific property we haven't discussed yet and is a bit tricky in JAX: keeping track of the running average. During every forward pass, we want to record the mean and standard deviation of the current batch, and update our current average over the past batches. However, this requires changing an input tensor, and returning this changed tensor again. In Flax, we can do this by defining the batch statistics as a mutable tensor. Check out our [Tutorial 5](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial5/Inception_ResNet_DenseNet.html) to see BatchNorm being used in practice with Flax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imJDmaj6DiL4"
      },
      "source": [
        "---\n",
        "\n",
        "[![Star our repository](https://img.shields.io/static/v1.svg?logo=star&label=⭐&message=Star%20Our%20Repository&color=yellow)](https://github.com/phlippe/uvadlc_notebooks/)  If you found this tutorial helpful, consider ⭐-ing our repository.    \n",
        "[![Ask questions](https://img.shields.io/static/v1.svg?logo=star&label=❔&message=Ask%20Questions&color=9cf)](https://github.com/phlippe/uvadlc_notebooks/issues)  For any questions, typos, or bugs that you found, please raise an issue on GitHub.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
